# PyTorch 场景的精度数据采集基线

## "tensor"模式采集数据量参考基线

该基线为pytorch框架下，使用"tensor"模式采集数据量参考基线。本基线测试了两个模型，分别为LLAMA2-7B和LLAMA2-13B，测试了不同采集模式下，不同global_batch_size下，单卡和8卡下，数据量的变化。

### LLAMA2-7B

<table>
    <tr><th>采集模式</th><th>global_batch_size</th><th>单卡</th><th>8卡</th></tr>
    </td><td rowspan="3">L0</td><td>1</td><td>7.8GB</td><td>63GB</td></tr>
    <tr><td>2</td><td>16GB</td><td>125GB</td></tr>
    <tr><td>3</td><td>24GB</td><td>187GB</td></tr>
    </td><td rowspan="3">L1</td><td>1</td><td>300.8GB</td><td>2.3TB</td></tr>
    <tr><td>2</td><td>480GB</td><td>3.6TB</td></tr>
    <tr><td>3</td><td>640GB</td><td>4.9TB</td></tr>
    </td><td rowspan="3">mix</td><td>1</td><td>313.6GB</td><td>2.4TB</td></tr>
    <tr><td>2</td><td>512GB</td><td>3.8TB</td></tr>
    <tr><td>3</td><td>672GB</td><td>5.1TB</td></tr>

</table>

### LLAMA2-13B

<table>
    <tr><th>采集模式</th><th>global_batch_size</th><th>单卡</th><th>8卡</th></tr>
    </td><td rowspan="3">L0</td><td>1</td><td>13GB</td><td>97GB</td></tr>
    <tr><td>2</td><td>25B</td><td>194GB</td></tr>
    <tr><td>3</td><td>37G</td><td>291GB</td></tr>
    </td><td rowspan="3">L1</td><td>1</td><td>440GB</td><td>3.4TB</td></tr>
    <tr><td>2</td><td>720GB</td><td>5.4TB</td></tr>
    <tr><td>3</td><td>960GB</td><td>7.3TB</td></tr>
    </td><td rowspan="3">mix</td><td>1</td><td>480GB</td><td>3.6TB</td></tr>
    <tr><td>2</td><td>720GB</td><td>5.6TB</td></tr>
    <tr><td>3</td><td>1000GB</td><td>7.7TB</td></tr>

</table>