import base64
import json
from mcp.server.fastmcp import FastMCP, Context
from mcp.types import TextContent, ImageContent
from playwright.async_api import Page
from browse_mcp.browse_manager import BrowserManager
from pydantic import BaseModel, Field
from browse_mcp.tools.playwright_tools import PlaywrightTools
import pathlib
from browse_mcp.tools.file_tools import FileTools

# from autogen_ext.agents.web_surfer._types import InteractiveRegion
from autogen_ext.agents.web_surfer.playwright_controller import PlaywrightController
from typing import (
    Any,
    AsyncGenerator,
    Dict,
    List,
    Optional,
    Sequence,
)


class SearchResult(BaseModel):
    """ç™¾åº¦æœç´¢ç»“æœçš„æ•°æ®æ¨¡å‹"""
    title: str = Field(description="æœç´¢ç»“æœçš„æ ‡é¢˜")
    url: str = Field(description="æœç´¢ç»“æœçš„URLé“¾æ¥")
    snippet: str = Field(description="æœç´¢ç»“æœçš„ç®€ä»‹æ‘˜è¦")
    source: Optional[str] = Field(None, description="æ¥æºç½‘ç«™")
    time: Optional[str] = Field(None, description="å‘å¸ƒæ—¶é—´ï¼ˆå¦‚æœæœ‰ï¼‰")
    
    class Config:
        # ç¡®ä¿JSONåºåˆ—åŒ–æ—¶ä¸å°†ä¸­æ–‡è½¬æ¢ä¸ºUnicodeç¼–ç 
        json_encoders = {
            str: lambda v: v
        }
        json_dumps_kwargs = {
            "ensure_ascii": False
        }
    
    def model_dump(self, **kwargs):
        """é‡å†™model_dumpæ–¹æ³•ï¼Œç¡®ä¿è¿”å›çš„JSONä¸ä½¿ç”¨Unicodeç¼–ç """
        # åˆå¹¶é»˜è®¤å‚æ•°å’Œä¼ å…¥çš„å‚æ•°
        dump_kwargs = {"exclude_none": True}
        dump_kwargs.update(kwargs)
        # è°ƒç”¨çˆ¶ç±»çš„model_dumpæ–¹æ³•
        result = super().model_dump(**dump_kwargs)
        return result

class BrowserNavigationServer(FastMCP):
    def __init__(self, server_name="browser-operation-server"):
        super().__init__(server_name)
        self.mcp = self
        self.browser_manager = BrowserManager()
        # self.llm_config = get_default_llm_config()
        # self.llm_client = LLMClient(self.llm_config)

        self.search_results_cache = {}
        self.current_page = 1
        self.current_query = ""
        self.total_pages = 1
        
        self.screenshots = dict()
        self.register_tools()
        self.register_resources()
        self.register_prompts()
        self.file_tools = FileTools()

    def register_tools(self):
        @self.mcp.tool(description="Navigate to a URL and get makrdown content")
        async def playwright_navigate(url: str):
            """Navigate to a URL and return the page content in markdown format."""
            try:
                page: Page = await self.browser_manager.ensure_browser()
                await page.goto(url=url, wait_until="load", timeout=30000)
                
                # è·å–é¡µé¢æ ‡é¢˜
                page_title = await page.title()
                
                # ä½¿ç”¨PlaywrightControllerè·å–é¡µé¢å†…å®¹çš„markdownæ ¼å¼
                playwright_controller = PlaywrightController()
                page_markdown = await playwright_controller.get_page_markdown(page)
                
                return {
                    "title": page_title,
                    "url": url,
                    "content": page_markdown
                }
            except Exception as e:
                raise ValueError(f"Navigation failed: {e}")
                
        @self.mcp.tool(description="åœ¨ç™¾åº¦ä¸Šæœç´¢å¹¶è·å–ç»“æœ")
        async def baidu_search(query: str, page: int = 1):
            """åœ¨ç™¾åº¦ä¸Šæ‰§è¡Œæœç´¢æŸ¥è¯¢å¹¶è¿”å›ç»“æœ
            
            ä¸ºäº†é¿å…è§¦å‘ç™¾åº¦éªŒè¯ç ï¼Œæœ¬æ–¹æ³•ä¼š:
            1. è®¾ç½®åˆç†çš„User-Agent
            2. æ¨¡æ‹ŸçœŸå®ç”¨æˆ·è¡Œä¸º
            3. æ§åˆ¶è¯·æ±‚é¢‘ç‡
            4. åœ¨éœ€è¦æ—¶å¤„ç†éªŒè¯ç 
            5. é€šè¿‡ç‚¹å‡»åˆ†é¡µæŒ‰é’®è·å–æ¯é¡µç»“æœ
            
            å‚æ•°:
                query: æœç´¢å…³é”®è¯
                page: æ£€ç´¢çš„é¡µæ•°
            """
            try:
                self.current_query = query
                self.current_page = page
                
                # å¯¼èˆªåˆ°ç™¾åº¦é¦–é¡µ
                search_url = f"https://www.baidu.com"
                
                # å¯¼èˆªåˆ°æœç´¢é¡µé¢
                browser_page: Page = await self.browser_manager.ensure_browser()

                # è®¾ç½®åˆç†çš„User-Agentå’Œå…¶ä»–è¯·æ±‚å¤´ï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
                # ä½¿ç”¨å¸¸è§çš„ç°ä»£æµè§ˆå™¨User-Agent
                user_agents = [
                    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
                    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Safari/605.1.15",
                    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36 Edg/92.0.902.55",
                    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:90.0) Gecko/20100101 Firefox/90.0"
                ]
                import random
                
                # éšæœºé€‰æ‹©ä¸€ä¸ªUser-Agent
                selected_user_agent = random.choice(user_agents)
                
                # è®¾ç½®é¢å¤–çš„è¯·æ±‚å¤´
                extra_headers = {
                    "User-Agent": selected_user_agent,
                    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
                    "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
                    "Accept-Encoding": "gzip, deflate, br",
                    "Connection": "keep-alive",
                    "Upgrade-Insecure-Requests": "1",
                    "Cache-Control": "max-age=0"
                }
                
                # è®¾ç½®è¯·æ±‚å¤´å¹¶å¯¼èˆªåˆ°æœç´¢é¡µé¢
                await browser_page.set_extra_http_headers(extra_headers)
                await browser_page.goto(url=search_url, wait_until="domcontentloaded", timeout=30000)
                
                # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
                await browser_page.wait_for_load_state("networkidle")
                
                # å®šä½æœç´¢æ¡†å¹¶è¾“å…¥å…³é”®è¯
                search_input_selector = "#kw"
                await browser_page.wait_for_selector(search_input_selector, timeout=5000)
                await browser_page.fill(search_input_selector, query)
                # ç‚¹å‡»æœç´¢æŒ‰é’®
                search_button_selector = "#su"
                await browser_page.wait_for_selector(search_button_selector, timeout=5000)
                await browser_page.click(search_button_selector)
                
                # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
                await browser_page.wait_for_load_state("networkidle")
                await browser_page.wait_for_selector(".result", timeout=5000)
                
                # æå–åˆ†é¡µä¿¡æ¯
                total_pages = await self._extract_pagination_info(browser_page)
                self.total_pages = total_pages
                # å¦‚æœéœ€è¦è·å–æ‰€æœ‰é¡µé¢çš„ç»“æœ
                page_results = await self._extract_search_results(browser_page)
                if total_pages > 1 and page > 1:
                    self.current_page = 2
                    # ä»å½“å‰é¡µå¼€å§‹ï¼Œè·å–åç»­æ‰€æœ‰é¡µé¢çš„ç»“æœ
                    while self.current_page <= page and self.current_page <= self.total_pages:
                        # æŸ¥æ‰¾ä¸‹ä¸€é¡µæŒ‰é’® - å°è¯•å¤šç§é€‰æ‹©å™¨
                        next_page_selector = "a.n:has-text('ä¸‹ä¸€é¡µ')"
                        clicked = False
                        
                        # ç­‰å¾…ä¸‹ä¸€é¡µæŒ‰é’®å‡ºç°
                        next_button = await browser_page.wait_for_selector(next_page_selector, timeout=15000)
                        if next_button:
                            # ç¡®ä¿æŒ‰é’®å¯è§ä¸”å¯ç‚¹å‡»
                            await next_button.scroll_into_view_if_needed()
                            await browser_page.click(next_page_selector)
                            clicked = True
                            # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
                            await browser_page.wait_for_load_state("networkidle")
                            await browser_page.wait_for_selector(".result", timeout=15000)
            
                        
                        if not clicked:
                            print("æ— æ³•æ‰¾åˆ°ä¸‹ä¸€é¡µæŒ‰é’®")
                            break
                        
                        # æ›´æ–°å½“å‰é¡µç 
                        self.current_page += 1
                        
                        # æ·»åŠ éšæœºå»¶è¿Ÿï¼Œé¿å…è§¦å‘éªŒè¯ç 
                        delay_time = random.uniform(1.0, 2.0)
                        await browser_page.wait_for_timeout(delay_time * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
                        current_page_results = await self._extract_search_results(browser_page)
                        # åˆå¹¶ç»“æœ
                        page_results.extend(current_page_results)
                # ç¼“å­˜ç»“æœ
                cache_key = f"{query}_{page}"
                self.search_results_cache[cache_key] = page_results
                
                # æ„å»ºè¿”å›ä¿¡æ¯
                # ä½¿ç”¨json.dumpsç¡®ä¿ä¸­æ–‡å­—ç¬¦ä¸ä¼šè¢«è½¬æ¢ä¸ºUnicodeç¼–ç 
                return {
                    "query": query,
                    "page": page,
                    "total_pages": total_pages,
                    "results": json.loads(json.dumps([result.model_dump(exclude_none=True) for result in page_results], ensure_ascii=False)),
                    "result_count": len(page_results)
                }
            except Exception as e:
                raise ValueError(f"æœç´¢å¤±è´¥: {e}")
    async def _extract_pagination_info(self, page: Page) -> int:
        """æå–åˆ†é¡µä¿¡æ¯"""
        try:
            # å°è¯•è·å–æ€»é¡µæ•°
            total_pages = await page.evaluate("""
                () => {
                    const pageInfo = document.querySelector('.page-inner');
                    if (pageInfo) {
                        const lastPage = pageInfo.querySelector('a:last-of-type');
                        if (lastPage && lastPage.textContent) {
                            const pageNum = parseInt(lastPage.textContent.trim());
                            return isNaN(pageNum) ? 1 : pageNum;
                        }
                    }
                    return 1; // é»˜è®¤ä¸º1é¡µ
                }
            """)
            return 10
        except Exception:
            return 1  # å¦‚æœæ— æ³•æå–ï¼Œé»˜è®¤ä¸º1é¡µ
    async def _simulate_human_behavior(self, page: Page):
        """æ¨¡æ‹ŸçœŸå®ç”¨æˆ·è¡Œä¸ºï¼Œéšæœºæ»šåŠ¨å’Œæš‚åœ"""
        import random
        import asyncio
        
        # éšæœºæ»šåŠ¨é¡µé¢
        for _ in range(random.randint(2, 5)):
            # éšæœºæ»šåŠ¨è·ç¦»
            scroll_distance = random.randint(300, 800)
            await page.evaluate(f"window.scrollBy(0, {scroll_distance})")
            
            # éšæœºæš‚åœæ—¶é—´
            pause_time = random.uniform(0.5, 2.0)
            await asyncio.sleep(pause_time)
        
        # æœ‰æ—¶å€™æ»šå›é¡¶éƒ¨
        if random.random() > 0.7:
            await page.evaluate("window.scrollTo(0, 0)")
            await asyncio.sleep(random.uniform(0.3, 1.0))
            
    async def _check_and_handle_captcha(self, page: Page) -> bool:
        """æ£€æŸ¥æ˜¯å¦å‡ºç°éªŒè¯ç å¹¶å°è¯•å¤„ç†
        
        è¿”å›å€¼:
            bool: å¦‚æœæ£€æµ‹åˆ°å¹¶å¤„ç†äº†éªŒè¯ç è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        # æ£€æŸ¥å¸¸è§çš„ç™¾åº¦éªŒè¯ç å…ƒç´ 
        captcha_selectors = [
            "#verify_img",  # å›¾ç‰‡éªŒè¯ç 
            ".vcode-spin",  # æ—‹è½¬éªŒè¯ç 
            ".vcode-slide",  # æ»‘åŠ¨éªŒè¯ç 
            "#seccodeImage",  # å®‰å…¨éªŒè¯ç å›¾ç‰‡
            ".vcode-body"  # éªŒè¯ç å®¹å™¨
        ]
        
        for selector in captcha_selectors:
            if await page.query_selector(selector) is not None:
                print("æ£€æµ‹åˆ°ç™¾åº¦éªŒè¯ç ï¼Œéœ€è¦äººå·¥å¤„ç†")
                
                # åœ¨æ§åˆ¶å°è®°å½•éªŒè¯ç å‡ºç°
                if hasattr(self, 'console_logs'):
                    self.console_logs.append("[è­¦å‘Š] æ£€æµ‹åˆ°ç™¾åº¦éªŒè¯ç ï¼Œè¯·æ‰‹åŠ¨å¤„ç†")
                
                # ç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨å¤„ç†éªŒè¯ç 
                # è¿™é‡Œæˆ‘ä»¬ç­‰å¾…30ç§’ï¼Œå‡è®¾ç”¨æˆ·ä¼šåœ¨è¿™æ®µæ—¶é—´å†…è§£å†³éªŒè¯ç 
                # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯èƒ½éœ€è¦æ›´å¤æ‚çš„æœºåˆ¶æ¥é€šçŸ¥ç”¨æˆ·å¹¶ç­‰å¾…éªŒè¯ç è§£å†³
                await page.wait_for_timeout(30000)  # ç­‰å¾…30ç§’
                
                # æ£€æŸ¥éªŒè¯ç æ˜¯å¦å·²è§£å†³
                if await page.query_selector(selector) is None:
                    return True  # éªŒè¯ç å·²è§£å†³
                
                # å¦‚æœéªŒè¯ç ä»ç„¶å­˜åœ¨ï¼Œå¯èƒ½éœ€è¦æ›´å¤šæ—¶é—´æˆ–å…¶ä»–å¤„ç†æ–¹å¼
                # è¿™é‡Œç®€å•åœ°å†ç­‰å¾…30ç§’
                await page.wait_for_timeout(30000)  # å†ç­‰å¾…30ç§’
                return True  # æ— è®ºéªŒè¯ç æ˜¯å¦è§£å†³ï¼Œæˆ‘ä»¬éƒ½è¿”å›Trueè¡¨ç¤ºå·²å°è¯•å¤„ç†
        
        return False  # æ²¡æœ‰æ£€æµ‹åˆ°éªŒè¯ç 
    
    async def _extract_search_results(self, page: Page) -> List[SearchResult]:
        """ä»ç™¾åº¦æœç´¢é¡µé¢æå–æœç´¢ç»“æœ"""
        results = []
        
        # ä½¿ç”¨JavaScriptæå–æœç´¢ç»“æœ
        raw_results = await page.evaluate("""
            () => {
                const resultElements = document.querySelectorAll('.result');
                return Array.from(resultElements).map(el => {
                    // æå–æ ‡é¢˜å’ŒURL
                    const titleEl = el.querySelector('.t a, .c-title a');
                    const title = titleEl ? titleEl.textContent.trim() : '';
                    const url = titleEl ? titleEl.href : '';
                    
                    // æå–æ‘˜è¦
                    const snippetEl = el.querySelector('.c-abstract, .content-abstract');
                    const snippet = snippetEl ? snippetEl.textContent.trim() : '';
                    
                    // æå–æ¥æºå’Œæ—¶é—´ï¼ˆå¦‚æœæœ‰ï¼‰
                    const sourceEl = el.querySelector('.c-author, .c-color-gray');
                    const source = sourceEl ? sourceEl.textContent.trim() : null;
                    
                    // æå–æ—¶é—´ï¼ˆé€šå¸¸åŒ…å«åœ¨æ¥æºä¿¡æ¯ä¸­ï¼‰
                    let time = null;
                    if (source) {
                        const timeMatch = source.match(/\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥|\d{1,2}å¤©å‰|\d{1,2}å°æ—¶å‰/);
                        time = timeMatch ? timeMatch[0] : null;
                    }
                    
                    return { title, url, snippet, source, time };
                });
            }
        """)
        
        # å°†åŸå§‹ç»“æœè½¬æ¢ä¸ºSearchResultå¯¹è±¡
        for item in raw_results:
            if item['title'] and item['url']:
                results.append(SearchResult(
                    title=item['title'],
                    url=item['url'],
                    snippet=item['snippet'] if item['snippet'] else "æ— æ‘˜è¦",
                    source=item['source'],
                    time=item['time']
                ))
        
        return results

        



    def register_resources(self):
        @self.mcp.resource("console://logs")
        async def get_console_logs() -> str:
            """Get a personalized greeting"""
            return TextContent(
                type="text", text="\n".join(self.browser_manager.console_logs)
            )

        @self.mcp.resource("screenshot://{name}")
        async def get_screenshot(name: str) -> str:
            """Get a screenshot by name"""
            screenshot_base64 = self.screenshots.get(name)
            if screenshot_base64:
                return ImageContent(
                    type="image",
                    data=screenshot_base64,
                    mimeType="image/png",
                    uri=f"screenshot://{name}",
                )
            else:
                raise ValueError(f"Screenshot {name} not found")

    def register_prompts(self):
        @self.mcp.prompt()
        async def hello_world(code: str) -> str:
            return f"Hello world:\n\n{code}"


""" 
When executing the MCP Inspector in a terminal, use the following command:

```bash
cmd> fastmcp dev ./server/browser_navigator_server.py:app
```

app = BrowserNavigationServer()

- `server/browser_navigator_server.py` specifies the file path.
- `app` refers to the server object created by `BrowserNavigationServer`.

After running the command, the following message will be displayed:

```
> Starting MCP Inspector...
> ğŸ” MCP Inspector is up and running at http://localhost:5173 ğŸš€
```

**Important:** Do not use `__main__` to launch the MCP Inspector. This will result in the following error:

    No server object found in **.py. Please either:
    1. Use a standard variable name (mcp, server, or app)
    2. Specify the object name with file:object syntax
"""

app = BrowserNavigationServer()
def main():
    app.run()

print("BrowserNavigationServer is running...")
# print all attributes of the mcp
# print(dir(app))


# if __name__ == "__main__":
#     app = BrowserNavigationServer()
#     app.run()
#     print("BrowserNavigationServer is running...")

