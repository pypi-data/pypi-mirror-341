{"title":"Multiple Hypothesis Testing Corrections","markdown":{"yaml":{"title":"Multiple Hypothesis Testing Corrections"},"headingText":"What is a Family-Wise Error Rate (FWER)?","containsRefs":false,"markdown":"\n\n\n\n\n\n\nWhen conducting online A/B tests or large-scale experiments, we often analyze multiple dependent variables simultaneously. Analyzing multiple KPIs introduces a significant statistical challenge: the multiple testing problem.\n\nIn classical hypothesis testing, the significance level $\\alpha$ controls the probability of a false positive (Type I error), typically $\\alpha=0.05$. While this ensures a 5% chance of a false positive for a single test, the likelihood of detecting at least one false positive grows rapidly when conducting multiple tests. For example, testing 20 KPIs independently at $\\alpha = 0.05$ results in a 64% chance of at least one false positive—calculated as $1 - (1 - 0.05)^{20} \\approx 0.64$. This issue, known as the multiple testing problem, can lead to false claims of significant effects when none exist.\n\nTo address this, the concept of controlling the **Familywise Error Rate (FWER)** has been widely adopted. FWER controls the probability of at least one Type I error across a family of hypotheses. Several correction methods exist to mitigate the multiple testing problem, including:\n\n- **Bonferroni Correction**: A simple and conservative method that adjusts the significance level for each test by dividing $\\alpha$ by the number of tests.\n- **Romano-Wolf & Westfall-Young Stepwise Procedures**: Two more powerful methods that use resampling techniques to control the FWER.\n\nThis vignette demonstrates how these methods effectively control the FWER in a variety of scenarios. We will compare their performance and highlight the trade-offs between simplicity and statistical power. Specifically, we show that while Bonferroni provides strong error control, it is conservative in many practical applications. In contrast, Romano-Wolf and Westfall-Young methods are more powerful, offering greater sensitivity to detect true effects while maintaining robust control of the FWER.\n\n\nSuppose that we are running an experiment and want to test if our treatment impacts 20 different dependent variables (KPIs). For any given independent test, the chance of a false positive is given by the (significance) **level** of the individual test, which is most commonly set to $\\alpha = 0.05$. Formally, we can define the false positive rate for a single hypothesis $H$ as:\n\n$$\nP(\\text{reject } H \\mid H \\text{ is true}) = \\alpha\n$$\n\nFor a **family of tests** $S = {s \\in \\{1, \\dots, P\\} }$ hypotheses $\\{H_{s}\\}_{s \\in S}$, we can analogously define the **family-wise error rate (FWER)** as:\n\n$$\nP(\\text{reject at least one } H_{s} \\text{ with } s \\in I) = \\alpha\n$$\n\nwhere $I$ is the set of **true hypotheses**. In other words, the FWER is the probability of making at least one false positive across all tests in the family.\n\n\n## Setup\n\nIn a first step, we create a data set with multiple (potentially correlated) dependent variables that share a common set of covariates. \nAll simulations in this notebook are greatly inspired by Clarke, Romano & Wolf (Stata Journal, 2020).\n\nNow that we have our data set at hand, we can fit 20 regression models - one for each dependent variable. To do so, we will use \npyfixest's multiple estimation syntax.\n\nWe see that our estimation produces multiple false positives for the effect of X1 on multiple dependent variables. Recall that \nwe had simulated X1 to have **no effect** on any of the dependent variables. Still, the estimation procedure produces a significant\neffect for X1 on multiple dependent variables. \n\n`PyFixest` provides three functions to adjust inference for multiple testing: `pf.bonferroni()`, `pf.rwolf()`, and `pf.wyoung()`.\nAll three share a common API.\n\nWe quickly see that the corrected p-values do not flag any false positives. \n\n## Controlling for the Familiy-Wise Error Rate (FWER)\n\nWe now show by means of simulation that the three methods control the family-wise error rate (FWER). To do so, we simulate 1000 \ndata sets imposing true nulls for the effect of X1 on all of 20 created dependent variables. \nFor each simulation, we then count if the methods flag more than one false positive and report our results. \n\nWe see that all three correction methods get close to the desired 5% level. In contrast, the uncorrected method produces the expected much higher family-wise error rate. \n\n## Power \n\nNow that we've seen that all three methods effectively handle false positives, let's see how well they avoid **false negatives**. \nIn other words, we will study how powerful all three methods are in detecting true effects. \n\nTo do so, we slightly have to adjust the data generating process. Instead of simulating the impact of X1 on all dependent variables \nto be zero (a true null effect), we will now simulate the impact of X1 to be $0.5$ for all dependent variables. Hence \nwe simulate **true positives** and count how often we correctly detect the true effect, or, equivalently stated, how often we correctly reject \nthe null of no treatment effect. \n\nWe will now study power more systematically via a simulation. More concretely, we will compute how often \nwe detect the **true effect** of **X1 on Y1, Y2, ..., etc** given a fixed sample size $N$ using \"uncorrected\" p-values, \nthe Bonferroni, Romano-Wolf and Westfall-Young methods. \n\nWe see that the \"unadjusted\" method detects the \"true effects\" at the highest frequency with on average 97% correctly detected effects. Does this mean that we should use uncorrected tests then? Well, maybe, but these do not control the family-wise error rate. While we have a better chance to detect a true effect, we also have a higher risk of flagging false positives. \n\nAdditionally, it looks as if the rwolf and wyoung methods detect the true positives at a slightly higher rate than the Bonferroni method. \n\nDo these findings generalize to other effect sizes? We can check this by simply imposing \ndifferent effects on the data generating process and repeating the previous exercise \nmultiple times. \n\nWe see that for any simulated effect size, the Romano-Wolf and Westfall-Young methods detect a higher share of true positives than the Bonferroni method: they have **higher power**.\n\n## Literature \n\n- Clarke, Damian, Joseph P. Romano, and Michael Wolf. \"The Romano–Wolf multiple-hypothesis correction in Stata.\" The Stata Journal 20.4 (2020): 812-843.\n- Romano, Joseph P., and Michael Wolf. \"Stepwise multiple testing as formalized data snooping.\" Econometrica 73.4 (2005): 1237-1282.\n- Westfall, Peter H., and S. Stanley Young. Resampling-based multiple testing: Examples and methods for p-value adjustment. Vol. 279. John Wiley & Sons, 1993.\n","srcMarkdownNoYaml":"\n\n\n\n\n\n\nWhen conducting online A/B tests or large-scale experiments, we often analyze multiple dependent variables simultaneously. Analyzing multiple KPIs introduces a significant statistical challenge: the multiple testing problem.\n\nIn classical hypothesis testing, the significance level $\\alpha$ controls the probability of a false positive (Type I error), typically $\\alpha=0.05$. While this ensures a 5% chance of a false positive for a single test, the likelihood of detecting at least one false positive grows rapidly when conducting multiple tests. For example, testing 20 KPIs independently at $\\alpha = 0.05$ results in a 64% chance of at least one false positive—calculated as $1 - (1 - 0.05)^{20} \\approx 0.64$. This issue, known as the multiple testing problem, can lead to false claims of significant effects when none exist.\n\nTo address this, the concept of controlling the **Familywise Error Rate (FWER)** has been widely adopted. FWER controls the probability of at least one Type I error across a family of hypotheses. Several correction methods exist to mitigate the multiple testing problem, including:\n\n- **Bonferroni Correction**: A simple and conservative method that adjusts the significance level for each test by dividing $\\alpha$ by the number of tests.\n- **Romano-Wolf & Westfall-Young Stepwise Procedures**: Two more powerful methods that use resampling techniques to control the FWER.\n\nThis vignette demonstrates how these methods effectively control the FWER in a variety of scenarios. We will compare their performance and highlight the trade-offs between simplicity and statistical power. Specifically, we show that while Bonferroni provides strong error control, it is conservative in many practical applications. In contrast, Romano-Wolf and Westfall-Young methods are more powerful, offering greater sensitivity to detect true effects while maintaining robust control of the FWER.\n\n## What is a Family-Wise Error Rate (FWER)? \n\nSuppose that we are running an experiment and want to test if our treatment impacts 20 different dependent variables (KPIs). For any given independent test, the chance of a false positive is given by the (significance) **level** of the individual test, which is most commonly set to $\\alpha = 0.05$. Formally, we can define the false positive rate for a single hypothesis $H$ as:\n\n$$\nP(\\text{reject } H \\mid H \\text{ is true}) = \\alpha\n$$\n\nFor a **family of tests** $S = {s \\in \\{1, \\dots, P\\} }$ hypotheses $\\{H_{s}\\}_{s \\in S}$, we can analogously define the **family-wise error rate (FWER)** as:\n\n$$\nP(\\text{reject at least one } H_{s} \\text{ with } s \\in I) = \\alpha\n$$\n\nwhere $I$ is the set of **true hypotheses**. In other words, the FWER is the probability of making at least one false positive across all tests in the family.\n\n\n## Setup\n\nIn a first step, we create a data set with multiple (potentially correlated) dependent variables that share a common set of covariates. \nAll simulations in this notebook are greatly inspired by Clarke, Romano & Wolf (Stata Journal, 2020).\n\nNow that we have our data set at hand, we can fit 20 regression models - one for each dependent variable. To do so, we will use \npyfixest's multiple estimation syntax.\n\nWe see that our estimation produces multiple false positives for the effect of X1 on multiple dependent variables. Recall that \nwe had simulated X1 to have **no effect** on any of the dependent variables. Still, the estimation procedure produces a significant\neffect for X1 on multiple dependent variables. \n\n`PyFixest` provides three functions to adjust inference for multiple testing: `pf.bonferroni()`, `pf.rwolf()`, and `pf.wyoung()`.\nAll three share a common API.\n\nWe quickly see that the corrected p-values do not flag any false positives. \n\n## Controlling for the Familiy-Wise Error Rate (FWER)\n\nWe now show by means of simulation that the three methods control the family-wise error rate (FWER). To do so, we simulate 1000 \ndata sets imposing true nulls for the effect of X1 on all of 20 created dependent variables. \nFor each simulation, we then count if the methods flag more than one false positive and report our results. \n\nWe see that all three correction methods get close to the desired 5% level. In contrast, the uncorrected method produces the expected much higher family-wise error rate. \n\n## Power \n\nNow that we've seen that all three methods effectively handle false positives, let's see how well they avoid **false negatives**. \nIn other words, we will study how powerful all three methods are in detecting true effects. \n\nTo do so, we slightly have to adjust the data generating process. Instead of simulating the impact of X1 on all dependent variables \nto be zero (a true null effect), we will now simulate the impact of X1 to be $0.5$ for all dependent variables. Hence \nwe simulate **true positives** and count how often we correctly detect the true effect, or, equivalently stated, how often we correctly reject \nthe null of no treatment effect. \n\nWe will now study power more systematically via a simulation. More concretely, we will compute how often \nwe detect the **true effect** of **X1 on Y1, Y2, ..., etc** given a fixed sample size $N$ using \"uncorrected\" p-values, \nthe Bonferroni, Romano-Wolf and Westfall-Young methods. \n\nWe see that the \"unadjusted\" method detects the \"true effects\" at the highest frequency with on average 97% correctly detected effects. Does this mean that we should use uncorrected tests then? Well, maybe, but these do not control the family-wise error rate. While we have a better chance to detect a true effect, we also have a higher risk of flagging false positives. \n\nAdditionally, it looks as if the rwolf and wyoung methods detect the true positives at a slightly higher rate than the Bonferroni method. \n\nDo these findings generalize to other effect sizes? We can check this by simply imposing \ndifferent effects on the data generating process and repeating the previous exercise \nmultiple times. \n\nWe see that for any simulated effect size, the Romano-Wolf and Westfall-Young methods detect a higher share of true positives than the Bonferroni method: they have **higher power**.\n\n## Literature \n\n- Clarke, Damian, Joseph P. Romano, and Michael Wolf. \"The Romano–Wolf multiple-hypothesis correction in Stata.\" The Stata Journal 20.4 (2020): 812-843.\n- Romano, Joseph P., and Michael Wolf. \"Stepwise multiple testing as formalized data snooping.\" Econometrica 73.4 (2005): 1237-1282.\n- Westfall, Peter H., and S. Stanley Young. Resampling-based multiple testing: Examples and methods for p-value adjustment. Vol. 279. John Wiley & Sons, 1993.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"python":"/pyfixest/.pixi/envs/docs/Scripts/python.exe","engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"multiple_testing.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.32","quartodoc":{"package":"pyfixest","title":"PyFixest Function Reference","parser":"numpy","rewrite_all_pages":false,"sidebar":"_sidebar.yml","sections":[{"title":"Estimation Functions","desc":"User facing estimation functions\n","contents":["estimation.estimation.feols","estimation.estimation.fepois","estimation.estimation.feglm","did.estimation.did2s","did.estimation.lpdid","did.estimation.event_study","estimation.bonferroni","estimation.rwolf"]},{"title":"Estimation Classes","desc":"Details on Methods and Attributes\n","contents":["estimation.feols_.Feols","estimation.fepois_.Fepois","estimation.feiv_.Feiv","estimation.feglm_.Feglm","estimation.felogit_.Felogit","estimation.feprobit_.Feprobit","estimation.fegaussian_.Fegaussian","estimation.feols_compressed_.FeolsCompressed"]},{"title":"Summarize and Visualize","desc":"Post-Processing of Estimation Results\n","contents":["did.visualize.panelview","report.summary","report.etable","report.dtable","report.coefplot","report.iplot","did.visualize.panelview"]},{"title":"Misc / Utilities","desc":"PyFixest internals and utilities\n","contents":["estimation.demean","estimation.detect_singletons","estimation.model_matrix_fixest"]}]},"title":"Multiple Hypothesis Testing Corrections"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}