{"title":"Difference-in-Differences Estimation","markdown":{"yaml":{"title":"Difference-in-Differences Estimation","format":{"html":{"html-table-processing":"none"}},"toc":true,"toc-title":"On this page","toc-location":"left"},"headingText":"Setup","containsRefs":false,"markdown":"\n\n`PyFixest` supports event study designs via the canonical two-way fixed effects design, the 2-Step imputation estimator, and local projections.\n\nSee also [NBER SI methods lectures on Linear Panel Event Studies](https://www.nber.org/conferences/si-2023-methods-lectures-linear-panel-event-studies).\n\n\n```{python}\nfrom importlib import resources\n\nimport pandas as pd\n\nimport pyfixest as pf\nfrom pyfixest.report.utils import rename_event_study_coefs\nfrom pyfixest.utils.dgps import get_sharkfin\n\n%load_ext watermark\n%watermark --iversions\n%load_ext autoreload\n%autoreload 2\n```\n\n\n\n```{python}\n# one-shot adoption data - parallel trends is true\ndf_one_cohort = get_sharkfin()\ndf_one_cohort.head()\n```\n\n\n\n```{python}\n# multi-cohort adoption data\ndf_multi_cohort = pd.read_csv(\n    resources.files(\"pyfixest.did.data\").joinpath(\"df_het.csv\")\n)\ndf_multi_cohort.head()\n```\n\n\n## Examining Treatment Timing\n\nBefore any DiD estimation, we need to examine the treatment timing, since it is crucial to our choice of estimator.\n\n\n```{python}\npf.panelview(\n    df_one_cohort,\n    unit=\"unit\",\n    time=\"year\",\n    treat=\"treat\",\n    collapse_to_cohort=True,\n    sort_by_timing=True,\n    ylab=\"Cohort\",\n    xlab=\"Year\",\n    title=\"Treatment Assignment Cohorts\",\n    figsize=(6, 5),\n)\n```\n\n\n\n```{python}\npf.panelview(\n    df_multi_cohort,\n    unit=\"unit\",\n    time=\"year\",\n    treat=\"treat\",\n    collapse_to_cohort=True,\n    sort_by_timing=True,\n    ylab=\"Cohort\",\n    xlab=\"Year\",\n    title=\"Treatment Assignment Cohorts\",\n    figsize=(6, 5),\n)\n```\n\n\nWe immediately see that we have staggered adoption of treatment in the second case, which implies that a naive application of 2WFE might yield biased estimates under substantial effect heterogeneity.\n\nWe can also plot treatment assignment in a disaggregated fashion, which gives us a sense of cohort sizes.\n\n\n```{python}\npf.panelview(\n    df_multi_cohort,\n    unit=\"unit\",\n    time=\"year\",\n    treat=\"treat\",\n    sort_by_timing=True,\n    ylab=\"Unit\",\n    xlab=\"Year\",\n    title=\"Treatment Assignment (all units)\",\n    figsize=(6, 5),\n)\n```\n\n## Inspecting the Outcome Variable\n\n`pf.panelview()` further allows us to inspect the \"outcome\" variable over time:\n\n\n```{python}\n#| fig-width: 0.4\n#| fig-height: 0.1\n\npf.panelview(\n    df_multi_cohort,\n    outcome=\"dep_var\",\n    unit=\"unit\",\n    time=\"year\",\n    treat=\"treat\",\n    collapse_to_cohort=True,\n    title=\"Outcome Plot\",\n    legend=True,\n    figsize=(7, 2.5),\n)\n```\n\n\nWe immediately see that the first cohort is switched into treatment in 2000, while the second cohort is switched into treatment by 2010.\nBefore each cohort is switched into treatment, the trends are parallel.\n\nWe can additionally inspect individual units by dropping the collapse_to_cohort argument. Because we have a large sample, we might want to inspect only a subset\nof units.\n\n\n```{python}\n#| fig-width: 4\n#| fig-height: 1\n\npf.panelview(\n    df_multi_cohort,\n    outcome=\"dep_var\",\n    unit=\"unit\",\n    time=\"year\",\n    treat=\"treat\",\n    subsamp=100,\n    title = \"Outcome Plot\",\n    legend=True,\n    figsize=(7, 2.5),\n)\n```\n\n\n## One-shot adoption: Static and Dynamic Specifications\n\nAfter taking a first look at the data, let's turn to estimation. We return to the `df_one_cohort` data set (without staggered treatment rollout).\n\n\n```{python}\nfit_static_twfe = pf.feols(\n    \"Y ~ treat | unit + year\",\n    df_one_cohort,\n    vcov={\"CRV1\": \"unit\"},\n)\nfit_static_twfe.summary()\n```\n\nSince this is a single-cohort dataset, this estimate is consistent for the ATT under parallel trends. We can estimate heterogeneous effects by time by interacting time with the treated group:\n\n\n```{python}\nfit_dynamic_twfe = pf.feols(\n    \"Y ~ i(year, ever_treated,  ref = 14) | unit + year\",\n    df_one_cohort,\n    vcov={\"CRV1\": \"unit\"},\n)\n```\n\n\n```{python}\nfit_dynamic_twfe.iplot(\n    coord_flip=False,\n    title=\"Event Study\",\n    figsize=[1200, 400],\n    yintercept=0,\n    xintercept=13.5,\n    labels=rename_event_study_coefs(fit_dynamic_twfe._coefnames),\n)\n```\n\n\nEvent study plots like this are very informative, as they allow us to visually inspect the parallel trends assumption and also the dynamic effects of the treatment.\n\nBased on a cursory glance, one would conclude that parallel trends does not hold because one of the pre-treatment coefficient has a confidence interval that does not include zero. However, we know that parallel trends is true because the treatment is randomly assigned in the underlying DGP.\n\n## Pointwise vs Simultaneous Inference in Event Studies\n\nThis is an example of a false positive in testing for pre-trends produced by _pointwise_ inference (where each element of the coefficient vector is tested separately).\n\nAs an alternative, we can use simultaneous confidence bands of the form $[a, b] = ([a_k, b_k])_{k=1}^K$ such that\n\n$$\nP(\\beta \\in [a, b]) = P(\\beta_k \\in [a_k, b_k] \\forall k) \\rightarrow 1 - \\alpha\n$$\n\nThese bands can be constructed by using a carefully chosen critical value $c$ that [accounts for the covariance between coefficients using the multiplier bootstrap](https://www.annualreviews.org/docserver/fulltext/statistics/10/1/annurev-statistics-040120-022239.pdf?expires=1724543273&id=id&accname=guest&checksum=0D11ADF816FFFA0AE21BD7EDC6DB1801#page=14). In pointwise inference, the critical value is $c = z_{1 - \\alpha/2} = 1.96$ for $\\alpha = 0.05$; the corresponding critical value for simultaneous inference is typically larger. These are also known as `sup-t` bands in the literature (see lec 3 of the NBER SI methods lectures linked above).\n\nThis is implemented in the `confint(joint=True)` method in the `feols` class. If we pass the `joint='both'` argument to `iplot`, we get the simultaneous confidence bands (for all event study coefficients) in addition to the pointwise confidence intervals. Note that simultaneous inference for all event study coefficients may be overly conservative, especially when the number of coefficients is large; one may instead choose to perform joint inference for [all pre-treatment coefficients and all post-treatment coefficients separately](https://gist.github.com/apoorvalal/8a7687d3620577fd5214f1d43fc740b3).\n\n\n```{python}\nfit_dynamic_twfe.iplot(\n    coord_flip=False,\n    title=\"Event Study\",\n    figsize=[1200, 400],\n    yintercept=0,\n    xintercept=13.5,\n    joint=\"both\",\n    labels=rename_event_study_coefs(fit_dynamic_twfe._coefnames),\n)\n```\n\n\nThe joint confidence bands are wider than the pointwise confidence intervals, and they include zero for all pre-treatment coefficients. This is consistent with the parallel trends assumption.\n\n## Event Study under Staggered Adoption via `feols()`, `event_study()`, `did2s()`,  `lpdid()`\n\nWe now return to the data set with staggered treatment rollout, `df_multi_cohort`.\n\n### Two-Way Fixed Effects\n\nAs a baseline model, we can estimate a simple two-way fixed effects DiD regression via `feols()`:\n\n\n```{python}\nfit_twfe = pf.feols(\n    \"dep_var ~ i(rel_year, ref=-1.0) | state + year\",\n    df_multi_cohort,\n    vcov={\"CRV1\": \"state\"},\n)\n```\n\nYou can also estimate a TWFE model via the `event_study()` function, which aims to provide a common interface to multiple\ndifference-in-differences implementations:\n\n```{python}\nfit_twfe_event = pf.event_study(\n    data=df_multi_cohort,\n    yname=\"dep_var\",\n    idname=\"unit\",\n    tname=\"year\",\n    gname=\"g\",\n    estimator=\"twfe\",\n)\n```\n\n### Fully-Interacted / Saturated Event Study (Sun-Abraham)\n\nIn a similar spirit, you can fit a fully-interacted difference-in-differences model by selecting the `estimator = \"saturated\"`:\n\n```{python}\nfit_saturated = pf.event_study(\n    data=df_multi_cohort,\n    yname=\"dep_var\",\n    idname=\"unit\",\n    tname=\"year\",\n    gname=\"g\",\n    estimator=\"saturated\",\n)\n\nfit_saturated.iplot()\n```\n\nWe can obtain treatment effects by period via the `aggregate()` method\n\n```{python}\nfit_saturated.aggregate(weighting = \"shares\")\n```\n\nand plot the effects\n\n```{python}\nfit_saturated.iplot_aggregate(weighting = \"shares\")\n```\n\n### When can we get away with using the two-way fixed effects regression?\n\nWe will motivate this section by lazily quoting the abstract of [Lal (2025)](https://arxiv.org/abs/2503.05125):\n\n> The use of the two-way fixed effects regression in empirical social science was historically motivated by folk wisdom that it uncovers the Average Treatment effect on the Treated (ATT) as in the canonical two-period two-group case. This belief has come under scrutiny recently due to recent results in applied econometrics showing that it fails to uncover meaningful averages of heterogeneous treatment effects in the presence of effect heterogeneity over time and across adoption cohorts, and several heterogeneity-robust alternatives have been proposed. However, these estimators often have higher variance and are therefore under-powered for many applications, which poses a bias-variance tradeoff that is challenging for researchers to navigate. In this paper, we propose simple tests of linear restrictions that can be used to test for differences in dynamic treatment effects over cohorts, which allows us to test for when the two-way fixed effects regression is likely to yield biased estimates of the ATT.\n\nYou can employ the proposed test after running a saturated event study by calling the `test_treatment_heterogeneity()` method:\n\n```{python}\nfit_saturated.test_treatment_heterogeneity()\n```\n\nIn this case, we might be willing to rely on the simple TWFE model to produce unbiased estimates. If we're not, two \"new\" difference-in-differences\nestimators are implemented (beyond the already-presented saturated Sun-Abraham approach) that produce unbiased estimates under staggered assignment and heterogeneous treatment effects: Gardner's 2-Step Estimator and the Local Projections estimator from Dube et al.\n\n### Gardner's 2-Step Estimator\n\nTo do the same via Gardners 2-stage estimator, we employ the the `pf.did2s()` function:\n\n```{python}\nfit_did2s = pf.did2s(\n    df_multi_cohort,\n    yname=\"dep_var\",\n    first_stage=\"~ 0 | state + year\",\n    second_stage=\"~i(rel_year,ref=-1.0)\",\n    treatment=\"treat\",\n    cluster=\"state\",\n)\n```\n\n### Local Projections (Dube et al)\n\nLast, we can estimate the ATT for each time period via local projections by using the `lpdid()` function:\n\n```{python}\nfit_lpdid = pf.lpdid(\n    data=df_multi_cohort,\n    yname=\"dep_var\",\n    gname=\"g\",\n    tname=\"year\",\n    idname=\"unit\",\n    vcov={\"CRV1\": \"state\"},\n    pre_window=-20,\n    post_window=20,\n    att=False,\n)\n```\n\nLet's look at some results:\n\n\n```{python}\nfigsize = [1200, 400]\n```\n\n\n```{python}\nfit_twfe.iplot(\n    coord_flip=False,\n    title=\"TWFE-Estimator\",\n    figsize=figsize,\n    xintercept=18.5,\n    yintercept=0,\n    labels=rename_event_study_coefs(fit_twfe._coefnames),  # rename coefficients\n).show()\n```\n\n\n```{python}\nfit_lpdid.iplot(\n    coord_flip=False,\n    title=\"Local-Projections-Estimator\",\n    figsize=figsize,\n    yintercept=0,\n    xintercept=18.5,\n).show()\n```\n\nWhat if we are not interested in the ATT per treatment period, but in a pooled effects?\n\n\n```{python}\nfit_twfe = pf.feols(\n    \"dep_var ~ i(treat) | unit + year\",\n    df_multi_cohort,\n    vcov={\"CRV1\": \"state\"},\n)\n\nfit_did2s = pf.did2s(\n    df_multi_cohort,\n    yname=\"dep_var\",\n    first_stage=\"~ 0 | unit + year\",\n    second_stage=\"~i(treat)\",\n    treatment=\"treat\",\n    cluster=\"state\",\n)\n\nfit_lpdid = pf.lpdid(\n    data=df_multi_cohort,\n    yname=\"dep_var\",\n    gname=\"g\",\n    tname=\"year\",\n    idname=\"unit\",\n    vcov={\"CRV1\": \"state\"},\n    pre_window=-20,\n    post_window=20,\n    att=True,\n)\npd.concat(\n    [\n        fit_twfe.tidy().assign(estimator=\"TWFE\"),\n        fit_did2s.tidy().assign(estimator=\"DID2s\"),\n        fit_lpdid.tidy().assign(estimator=\"LPDID\").drop(\"N\", axis=1),\n    ],\n    axis=0,\n)\n```\n","srcMarkdownNoYaml":"\n\n`PyFixest` supports event study designs via the canonical two-way fixed effects design, the 2-Step imputation estimator, and local projections.\n\nSee also [NBER SI methods lectures on Linear Panel Event Studies](https://www.nber.org/conferences/si-2023-methods-lectures-linear-panel-event-studies).\n\n## Setup\n\n```{python}\nfrom importlib import resources\n\nimport pandas as pd\n\nimport pyfixest as pf\nfrom pyfixest.report.utils import rename_event_study_coefs\nfrom pyfixest.utils.dgps import get_sharkfin\n\n%load_ext watermark\n%watermark --iversions\n%load_ext autoreload\n%autoreload 2\n```\n\n\n\n```{python}\n# one-shot adoption data - parallel trends is true\ndf_one_cohort = get_sharkfin()\ndf_one_cohort.head()\n```\n\n\n\n```{python}\n# multi-cohort adoption data\ndf_multi_cohort = pd.read_csv(\n    resources.files(\"pyfixest.did.data\").joinpath(\"df_het.csv\")\n)\ndf_multi_cohort.head()\n```\n\n\n## Examining Treatment Timing\n\nBefore any DiD estimation, we need to examine the treatment timing, since it is crucial to our choice of estimator.\n\n\n```{python}\npf.panelview(\n    df_one_cohort,\n    unit=\"unit\",\n    time=\"year\",\n    treat=\"treat\",\n    collapse_to_cohort=True,\n    sort_by_timing=True,\n    ylab=\"Cohort\",\n    xlab=\"Year\",\n    title=\"Treatment Assignment Cohorts\",\n    figsize=(6, 5),\n)\n```\n\n\n\n```{python}\npf.panelview(\n    df_multi_cohort,\n    unit=\"unit\",\n    time=\"year\",\n    treat=\"treat\",\n    collapse_to_cohort=True,\n    sort_by_timing=True,\n    ylab=\"Cohort\",\n    xlab=\"Year\",\n    title=\"Treatment Assignment Cohorts\",\n    figsize=(6, 5),\n)\n```\n\n\nWe immediately see that we have staggered adoption of treatment in the second case, which implies that a naive application of 2WFE might yield biased estimates under substantial effect heterogeneity.\n\nWe can also plot treatment assignment in a disaggregated fashion, which gives us a sense of cohort sizes.\n\n\n```{python}\npf.panelview(\n    df_multi_cohort,\n    unit=\"unit\",\n    time=\"year\",\n    treat=\"treat\",\n    sort_by_timing=True,\n    ylab=\"Unit\",\n    xlab=\"Year\",\n    title=\"Treatment Assignment (all units)\",\n    figsize=(6, 5),\n)\n```\n\n## Inspecting the Outcome Variable\n\n`pf.panelview()` further allows us to inspect the \"outcome\" variable over time:\n\n\n```{python}\n#| fig-width: 0.4\n#| fig-height: 0.1\n\npf.panelview(\n    df_multi_cohort,\n    outcome=\"dep_var\",\n    unit=\"unit\",\n    time=\"year\",\n    treat=\"treat\",\n    collapse_to_cohort=True,\n    title=\"Outcome Plot\",\n    legend=True,\n    figsize=(7, 2.5),\n)\n```\n\n\nWe immediately see that the first cohort is switched into treatment in 2000, while the second cohort is switched into treatment by 2010.\nBefore each cohort is switched into treatment, the trends are parallel.\n\nWe can additionally inspect individual units by dropping the collapse_to_cohort argument. Because we have a large sample, we might want to inspect only a subset\nof units.\n\n\n```{python}\n#| fig-width: 4\n#| fig-height: 1\n\npf.panelview(\n    df_multi_cohort,\n    outcome=\"dep_var\",\n    unit=\"unit\",\n    time=\"year\",\n    treat=\"treat\",\n    subsamp=100,\n    title = \"Outcome Plot\",\n    legend=True,\n    figsize=(7, 2.5),\n)\n```\n\n\n## One-shot adoption: Static and Dynamic Specifications\n\nAfter taking a first look at the data, let's turn to estimation. We return to the `df_one_cohort` data set (without staggered treatment rollout).\n\n\n```{python}\nfit_static_twfe = pf.feols(\n    \"Y ~ treat | unit + year\",\n    df_one_cohort,\n    vcov={\"CRV1\": \"unit\"},\n)\nfit_static_twfe.summary()\n```\n\nSince this is a single-cohort dataset, this estimate is consistent for the ATT under parallel trends. We can estimate heterogeneous effects by time by interacting time with the treated group:\n\n\n```{python}\nfit_dynamic_twfe = pf.feols(\n    \"Y ~ i(year, ever_treated,  ref = 14) | unit + year\",\n    df_one_cohort,\n    vcov={\"CRV1\": \"unit\"},\n)\n```\n\n\n```{python}\nfit_dynamic_twfe.iplot(\n    coord_flip=False,\n    title=\"Event Study\",\n    figsize=[1200, 400],\n    yintercept=0,\n    xintercept=13.5,\n    labels=rename_event_study_coefs(fit_dynamic_twfe._coefnames),\n)\n```\n\n\nEvent study plots like this are very informative, as they allow us to visually inspect the parallel trends assumption and also the dynamic effects of the treatment.\n\nBased on a cursory glance, one would conclude that parallel trends does not hold because one of the pre-treatment coefficient has a confidence interval that does not include zero. However, we know that parallel trends is true because the treatment is randomly assigned in the underlying DGP.\n\n## Pointwise vs Simultaneous Inference in Event Studies\n\nThis is an example of a false positive in testing for pre-trends produced by _pointwise_ inference (where each element of the coefficient vector is tested separately).\n\nAs an alternative, we can use simultaneous confidence bands of the form $[a, b] = ([a_k, b_k])_{k=1}^K$ such that\n\n$$\nP(\\beta \\in [a, b]) = P(\\beta_k \\in [a_k, b_k] \\forall k) \\rightarrow 1 - \\alpha\n$$\n\nThese bands can be constructed by using a carefully chosen critical value $c$ that [accounts for the covariance between coefficients using the multiplier bootstrap](https://www.annualreviews.org/docserver/fulltext/statistics/10/1/annurev-statistics-040120-022239.pdf?expires=1724543273&id=id&accname=guest&checksum=0D11ADF816FFFA0AE21BD7EDC6DB1801#page=14). In pointwise inference, the critical value is $c = z_{1 - \\alpha/2} = 1.96$ for $\\alpha = 0.05$; the corresponding critical value for simultaneous inference is typically larger. These are also known as `sup-t` bands in the literature (see lec 3 of the NBER SI methods lectures linked above).\n\nThis is implemented in the `confint(joint=True)` method in the `feols` class. If we pass the `joint='both'` argument to `iplot`, we get the simultaneous confidence bands (for all event study coefficients) in addition to the pointwise confidence intervals. Note that simultaneous inference for all event study coefficients may be overly conservative, especially when the number of coefficients is large; one may instead choose to perform joint inference for [all pre-treatment coefficients and all post-treatment coefficients separately](https://gist.github.com/apoorvalal/8a7687d3620577fd5214f1d43fc740b3).\n\n\n```{python}\nfit_dynamic_twfe.iplot(\n    coord_flip=False,\n    title=\"Event Study\",\n    figsize=[1200, 400],\n    yintercept=0,\n    xintercept=13.5,\n    joint=\"both\",\n    labels=rename_event_study_coefs(fit_dynamic_twfe._coefnames),\n)\n```\n\n\nThe joint confidence bands are wider than the pointwise confidence intervals, and they include zero for all pre-treatment coefficients. This is consistent with the parallel trends assumption.\n\n## Event Study under Staggered Adoption via `feols()`, `event_study()`, `did2s()`,  `lpdid()`\n\nWe now return to the data set with staggered treatment rollout, `df_multi_cohort`.\n\n### Two-Way Fixed Effects\n\nAs a baseline model, we can estimate a simple two-way fixed effects DiD regression via `feols()`:\n\n\n```{python}\nfit_twfe = pf.feols(\n    \"dep_var ~ i(rel_year, ref=-1.0) | state + year\",\n    df_multi_cohort,\n    vcov={\"CRV1\": \"state\"},\n)\n```\n\nYou can also estimate a TWFE model via the `event_study()` function, which aims to provide a common interface to multiple\ndifference-in-differences implementations:\n\n```{python}\nfit_twfe_event = pf.event_study(\n    data=df_multi_cohort,\n    yname=\"dep_var\",\n    idname=\"unit\",\n    tname=\"year\",\n    gname=\"g\",\n    estimator=\"twfe\",\n)\n```\n\n### Fully-Interacted / Saturated Event Study (Sun-Abraham)\n\nIn a similar spirit, you can fit a fully-interacted difference-in-differences model by selecting the `estimator = \"saturated\"`:\n\n```{python}\nfit_saturated = pf.event_study(\n    data=df_multi_cohort,\n    yname=\"dep_var\",\n    idname=\"unit\",\n    tname=\"year\",\n    gname=\"g\",\n    estimator=\"saturated\",\n)\n\nfit_saturated.iplot()\n```\n\nWe can obtain treatment effects by period via the `aggregate()` method\n\n```{python}\nfit_saturated.aggregate(weighting = \"shares\")\n```\n\nand plot the effects\n\n```{python}\nfit_saturated.iplot_aggregate(weighting = \"shares\")\n```\n\n### When can we get away with using the two-way fixed effects regression?\n\nWe will motivate this section by lazily quoting the abstract of [Lal (2025)](https://arxiv.org/abs/2503.05125):\n\n> The use of the two-way fixed effects regression in empirical social science was historically motivated by folk wisdom that it uncovers the Average Treatment effect on the Treated (ATT) as in the canonical two-period two-group case. This belief has come under scrutiny recently due to recent results in applied econometrics showing that it fails to uncover meaningful averages of heterogeneous treatment effects in the presence of effect heterogeneity over time and across adoption cohorts, and several heterogeneity-robust alternatives have been proposed. However, these estimators often have higher variance and are therefore under-powered for many applications, which poses a bias-variance tradeoff that is challenging for researchers to navigate. In this paper, we propose simple tests of linear restrictions that can be used to test for differences in dynamic treatment effects over cohorts, which allows us to test for when the two-way fixed effects regression is likely to yield biased estimates of the ATT.\n\nYou can employ the proposed test after running a saturated event study by calling the `test_treatment_heterogeneity()` method:\n\n```{python}\nfit_saturated.test_treatment_heterogeneity()\n```\n\nIn this case, we might be willing to rely on the simple TWFE model to produce unbiased estimates. If we're not, two \"new\" difference-in-differences\nestimators are implemented (beyond the already-presented saturated Sun-Abraham approach) that produce unbiased estimates under staggered assignment and heterogeneous treatment effects: Gardner's 2-Step Estimator and the Local Projections estimator from Dube et al.\n\n### Gardner's 2-Step Estimator\n\nTo do the same via Gardners 2-stage estimator, we employ the the `pf.did2s()` function:\n\n```{python}\nfit_did2s = pf.did2s(\n    df_multi_cohort,\n    yname=\"dep_var\",\n    first_stage=\"~ 0 | state + year\",\n    second_stage=\"~i(rel_year,ref=-1.0)\",\n    treatment=\"treat\",\n    cluster=\"state\",\n)\n```\n\n### Local Projections (Dube et al)\n\nLast, we can estimate the ATT for each time period via local projections by using the `lpdid()` function:\n\n```{python}\nfit_lpdid = pf.lpdid(\n    data=df_multi_cohort,\n    yname=\"dep_var\",\n    gname=\"g\",\n    tname=\"year\",\n    idname=\"unit\",\n    vcov={\"CRV1\": \"state\"},\n    pre_window=-20,\n    post_window=20,\n    att=False,\n)\n```\n\nLet's look at some results:\n\n\n```{python}\nfigsize = [1200, 400]\n```\n\n\n```{python}\nfit_twfe.iplot(\n    coord_flip=False,\n    title=\"TWFE-Estimator\",\n    figsize=figsize,\n    xintercept=18.5,\n    yintercept=0,\n    labels=rename_event_study_coefs(fit_twfe._coefnames),  # rename coefficients\n).show()\n```\n\n\n```{python}\nfit_lpdid.iplot(\n    coord_flip=False,\n    title=\"Local-Projections-Estimator\",\n    figsize=figsize,\n    yintercept=0,\n    xintercept=18.5,\n).show()\n```\n\nWhat if we are not interested in the ATT per treatment period, but in a pooled effects?\n\n\n```{python}\nfit_twfe = pf.feols(\n    \"dep_var ~ i(treat) | unit + year\",\n    df_multi_cohort,\n    vcov={\"CRV1\": \"state\"},\n)\n\nfit_did2s = pf.did2s(\n    df_multi_cohort,\n    yname=\"dep_var\",\n    first_stage=\"~ 0 | unit + year\",\n    second_stage=\"~i(treat)\",\n    treatment=\"treat\",\n    cluster=\"state\",\n)\n\nfit_lpdid = pf.lpdid(\n    data=df_multi_cohort,\n    yname=\"dep_var\",\n    gname=\"g\",\n    tname=\"year\",\n    idname=\"unit\",\n    vcov={\"CRV1\": \"state\"},\n    pre_window=-20,\n    post_window=20,\n    att=True,\n)\npd.concat(\n    [\n        fit_twfe.tidy().assign(estimator=\"TWFE\"),\n        fit_did2s.tidy().assign(estimator=\"DID2s\"),\n        fit_lpdid.tidy().assign(estimator=\"LPDID\").drop(\"N\", axis=1),\n    ],\n    axis=0,\n)\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"python":"/pyfixest/.pixi/envs/docs/Scripts/python.exe","engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"html-table-processing":"none"},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"difference-in-differences.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.32","quartodoc":{"package":"pyfixest","title":"PyFixest Function Reference","parser":"numpy","rewrite_all_pages":false,"sidebar":"_sidebar.yml","sections":[{"title":"Estimation Functions","desc":"User facing estimation functions\n","contents":["estimation.estimation.feols","estimation.estimation.fepois","estimation.estimation.feglm","did.estimation.did2s","did.estimation.lpdid","did.estimation.event_study","estimation.bonferroni","estimation.rwolf"]},{"title":"Estimation Classes","desc":"Details on Methods and Attributes\n","contents":["estimation.feols_.Feols","estimation.fepois_.Fepois","estimation.feiv_.Feiv","estimation.feglm_.Feglm","estimation.felogit_.Felogit","estimation.feprobit_.Feprobit","estimation.fegaussian_.Fegaussian","estimation.feols_compressed_.FeolsCompressed"]},{"title":"Summarize and Visualize","desc":"Post-Processing of Estimation Results\n","contents":["did.visualize.panelview","report.summary","report.etable","report.dtable","report.coefplot","report.iplot","did.visualize.panelview"]},{"title":"Misc / Utilities","desc":"PyFixest internals and utilities\n","contents":["estimation.demean","estimation.detect_singletons","estimation.model_matrix_fixest"]}]},"title":"Difference-in-Differences Estimation","toc-title":"On this page","toc-location":"left"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}