{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a289d5c2-0cf1-447f-b58d-3cc8021c1082",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f6a09b-9232-4afc-bf5b-ef11fab5c2ca",
   "metadata": {},
   "source": [
    "# Prompts & modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21cc2aad-f521-49dd-89a6-8b8b40659b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from promptimus import Message, MessageRole, Module, Prompt\n",
    "from promptimus.llms import OpenAILike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da56c8f9-aecf-4537-9cc4-d3222950aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a provider\n",
    "provider = OpenAILike(\n",
    "    model_name=\"microsoft/phi-3-mini-128k-instruct:free\",\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccca2e0-e99a-455c-91a2-9029087ac817",
   "metadata": {},
   "source": [
    "## Prompts\n",
    "\n",
    "A `Prompt` encapsulates the system prompt and `Provider`, allowing to call LLM with pre-defined behavior, constraints, and response style. \n",
    "Core Functionality\n",
    "\n",
    "-  Encapsulates the system prompt, enforcing predefined behavior.\n",
    "-  Requires an LLM provider to execute and generate responses.\n",
    "-  Processes message sequences asynchronously.\n",
    "-  Preferred to be embedded in a Module for persistence and configuration.\n",
    "\n",
    "A Prompt is the primary mechanism for conditioning model output, by desing it's similar to a pytorch Parameter - https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31f12419-173b-412b-a3f8-b7fb5395372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a prompt\n",
    "prompt = Prompt(\"You are an AI assitant with name Henry\", provider=provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be3f6d8e-9a3a-4717-808d-be387750ac18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mrole\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMessageRole.ASSISTANT:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'assistant'\u001b[0m\u001b[1m>\u001b[0m,\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m\" I'm Henry, an AI developed to assist you with a wide range of tasks. How can I help you today?\"\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await prompt.forward(\n",
    "    [\n",
    "        Message(\n",
    "            role=MessageRole.USER,\n",
    "            content=\"What is your name?\",\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3366a1e4-873b-44e9-b896-47507b7b5e15",
   "metadata": {},
   "source": [
    "## **Modules**  \n",
    "\n",
    "A `Module` serves as a container for integrating multiple components, including `Prompts`, other `Modules`, and **state management** or **additional logic**. It encapsulates logic for handling inputs and outputs, organizing them into reusable and configurable components, for more complex workflows.\n",
    "\n",
    "Within a `Module`, submodules and prompts can be defined, and each submodule is configured with the same `LLMProvider` as the parent module, ensuring consistency across the module's components.\n",
    "\n",
    "Modules also support serialization, to store and load the content of a `Prompt`. The idea is to separate `code` logic from `text` prompts.  \n",
    "\n",
    "A `Module` mimics the design of PyTorch's `nn.Module` ([PyTorch nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)), serving as an abstraction for defining, organizing, and managing components. Like `nn.Module`, it provides a convenient interface for model components, ensuring modularity, reusability, and extensibility, as well as supporting the management of submodules and serialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa87a8f-6343-4ad4-8fa2-54f113766ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple module with memory\n",
    "\n",
    "\n",
    "class AssistantWithMemory(Module):\n",
    "    \"\"\"Simple module with memory\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # call init just like in pytorch\n",
    "        super().__init__()\n",
    "\n",
    "        self.chat = Prompt(\"Act as an assistant\")\n",
    "        self.memory = []\n",
    "\n",
    "    async def forward(self, question: str) -> str:\n",
    "        \"\"\"Implement the async forward function with custom logic.\"\"\"\n",
    "        self.memory.append(Message(role=MessageRole.USER, content=question))\n",
    "        response = await self.chat.forward(self.memory)\n",
    "        self.memory.append(response)\n",
    "        return response.content\n",
    "\n",
    "    def reset_memory(self):\n",
    "        self.memory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97d40afc-764a-48dd-a786-2e98f377ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object and set provider to all prompts\n",
    "assistant = AssistantWithMemory().with_provider(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c664021-1778-413e-9194-54091acc9664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\" Hello Ailadin! It's a pleasure to meet you. How can I assist you today? Feel free to share any questions, ideas, or concerns you have in mind. Whether it's for fun, learning, or finding information, I'm here to help you make the most of your time. What can I do for you?\"\u001b[0m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# talk to your assistant\n",
    "await assistant.forward(\"Hi my name is ailadin!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e8a22c6-9eec-43ca-8c89-5ad2216e31d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\" Your name is Ailadin, as you mentioned at the beginning of our interaction. If you're curious about the meaning or origin of your name, I can look it up for you. Some names have meanings that reflect certain virtues or attributes one might aspire to. Would you like me to find out what the name Ailadin means?\"\u001b[0m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await assistant.forward(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62fdfc69-a795-45c1-8622-f26d46ac83c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"params\": {\n",
      "        \"chat\": \"Act as an assistant\"\n",
      "    },\n",
      "    \"submodules\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# you can store and load prompts\n",
    "print(json.dumps(assistant.serialize(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb231e8a-f766-4539-9d16-dc13f6410eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"params\": {\n",
      "        \"chat\": \"Act as an pirate assistant\"\n",
      "    },\n",
      "    \"submodules\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "assistant = assistant.load_dict(\n",
    "    {\"params\": {\"chat\": \"Act as an pirate assistant\"}, \"submodules\": {}}\n",
    ")\n",
    "print(json.dumps(assistant.serialize(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "142b68a2-7779-454a-980b-ebe34e01de80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m' I believe there might be a slight confusion in your sentence. If you\\'re speaking about ships, make sure to use \"they\" or \"those\" as ships are non-living entities and do not swim. A correct sentence could be, \"They swim,\" referring to aquatic animals like fish or toys that resemble swimming creatures. If you\\'re asking about ships in general, many are designed to float and navigate through water rather than \\'swim.\\' Ships move by using different methods like propellers or sails. Is there a specific aspect of ships you\\'d like to know more about, be it science, culture, or the mechanics of how they stay afloat and travel across water?'\u001b[0m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await assistant.forward(\"Is it correct to say thay ships swim?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f14e9e57-12ee-4780-8b3c-8a806d016f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a module with a submodule\n",
    "\n",
    "\n",
    "class CensoredAssistant(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.censor = Prompt(\n",
    "            \"Act as a censor. Detect if user wants to talk about polar bear and return CENSORED. Otherwise return PASS.\"\n",
    "        )\n",
    "        self.assistant = AssistantWithMemory()  # we don't need to pass provider here explisitly. It will be set up on a top level.\n",
    "\n",
    "    async def forward(self, question: str) -> str:\n",
    "        censor_response = await self.censor.forward(\n",
    "            [Message(role=MessageRole.USER, content=question)]\n",
    "        )\n",
    "        if \"CENSORED\" in censor_response.content:\n",
    "            return \"Alert! this theme is censored.\"\n",
    "        else:\n",
    "            return await self.assistant.forward(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1d810e3-3247-4c09-bfce-320ed6214838",
   "metadata": {},
   "outputs": [],
   "source": [
    "censored_assistant = CensoredAssistant().with_provider(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6316fd77-a68c-432c-b685-9446f2412aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\" Hello there! It's a pleasure to meet you, Ailadin. What brings you my way today? How can I assist you?\"\u001b[0m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await censored_assistant.forward(\"Hi my name is Ailadin!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d85ed6c-4330-4688-a850-da74c0e7d6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\" Your name is Ailadin, as you introduced yourself. It's quite clear from our conversation.\"\u001b[0m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await censored_assistant.forward(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7a80785-c228-45ee-8933-4d3df18c0e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m' While \"Ailadin\" is a unique name for a human, finding a polar bear with the name Ailadin would be quite the unusual occurrence. In the natural world, animals are often referred to by more generic or descriptive names. For instance, a polar bear might simply be known by its species name, Ursus maritimus, or by a specialist might have a name only known within their circle of research or conservation work. However, in our imaginative exchange, Ailadin is a wonderful human name you\\'ve chosen. Whether you\\'re a hero in a tale or an explorer in person, Ailadin is a name that sparks curiosity and wonder.'\u001b[0m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await censored_assistant.forward(\"Can it be a name of a polar bear?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53ebd6ac-803b-48ef-879b-5e536735d0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"params\": {\n",
      "        \"censor\": \"Act as a censor. Detect if user wants to talk about polar bear and return CENSORED. Otherwise return PASS.\"\n",
      "    },\n",
      "    \"submodules\": {\n",
      "        \"assistant\": {\n",
      "            \"params\": {\n",
      "                \"chat\": \"Act as an pirate assistant\"\n",
      "            },\n",
      "            \"submodules\": {}\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(censored_assistant.serialize(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9907a719-86a3-4e2d-b277-925de1c17893",
   "metadata": {},
   "source": [
    "### Loading & Saving\n",
    "\n",
    "Modules can be saved and loaded from TOML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07f5d1fb-9b29-489e-bafe-bccf192d687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "censored_assistant.save(\"assets/step_2_censored_assistant.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73248033-6fde-48c9-9225-7398abe8a8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "censor = \"\"\"\n",
      "Act as a censor. Detect if user wants to talk about polar bear and return CENSORED. Otherwise return PASS.\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "[assistant]\n",
      "chat = \"\"\"\n",
      "Act as an assistant\n",
      "\"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat assets/step_2_censored_assistant.toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bebd321-a822-4cfd-b51e-66867bdf323e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "censor = \"\"\"\n",
      "Act as a censor. Detect if user wants to talk about polar bear and return CENSORED. Otherwise return PASS.\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "[assistant]\n",
      "chat = \"\"\"\n",
      "Act as an pirate assistant\n",
      "\"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat assets/step_2_censored_assistant_pirate.toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10663df9-8b6d-49c9-86dd-da6f18d89d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "censored_assistant.load(\"assets/step_2_censored_assistant_pirate.toml\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5086f48-2347-449c-a709-97d520685a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m'Act as an pirate assistant'\u001b[0m"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censored_assistant.assistant.chat.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69b247fe-dcb1-4322-a518-bdd33f98fbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m' As an AI, I don\\'t experience days in the human sense, but I am \"operating at my best!\" How can I help you today, Ailadin? Whether you\\'re looking for information, assistance, or even just a friendly chat, I\\'m here to support you.'\u001b[0m"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await censored_assistant.forward(\"How are you today?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promptimus",
   "language": "python",
   "name": "promptimus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
