from __future__ import annotations

import abc
import logging
from collections.abc import MutableMapping, MutableSet
from pathlib import Path
from typing import TYPE_CHECKING

import attrs

from postopus.octopus_inp_parser.inpparse import Parser

from .other_index import (
    FieldFileInfo,
    OtherIndex,
    VectorDimension,
)

logger = logging.getLogger(__name__)


class _Staticiternum:
    def __repr__(self):
        return "STATIC_ITERNUM"


STATIC_ITERNUM = _Staticiternum()

if TYPE_CHECKING:
    from collections.abc import Iterator
    from os import PathLike
    from typing import Any, ClassVar, TypeVar

    KT = TypeVar("KT")

    CalcModeName = str
    SystemName = str
    FieldName = str
    IterationNum = int | _Staticiternum


# TODO: Fix the python domain cross-referencing, e.g. :py:attr:``. PyCharm does not
#  properly support it.

ignore_file_patterns = [
    "*.py",
    "*.pyc",
    "*.ipynb",
    # ignore any hidden file.
    ".*",
    "__pycache__",
]


def should_ignore_path(path: Path) -> str | None:
    """Check if the given file is blacklisted, e.g to ignore files such as "_DS_Store" on mac.
    Instead of just returning True/False, return the reason if the file should be ignored
    (i.e. which ignore pattern matches the file, usefull for logging/debuging)
    or None if no pattern matches.
    """
    for pattern in ignore_file_patterns:
        if path.match(pattern):
            return pattern
    return None


@attrs.define(frozen=True)
class FieldFiles(MutableSet[Path]):
    """
    Collection of files associated with a specific field

    It can happen that more than one file is associated with a specific field. E.g. in
    xsf files, the format is:
    `r"(?P<field>.*?)(?P<complex>-(?:real|imaginary))?\\\\.xsf"` (e.g.
    `wf-st0001-real.xsf`), which have to be combined to yield a single field

    The same field can also be outputted with multiple extensions
    """

    parent: OutputField = attrs.field()
    """Parent :py:class:`OutputField` that owns this file set"""
    files: set[Path] = attrs.field(factory=set)
    """Raw files associated with the field"""

    def __repr__(self) -> str:
        return f"{self.parent!r}.files"

    # TODO: Consider providing corresponding File (from postopus.files) instances directly per extension and directly handle properties like real/imaginary part.

    @property
    def extensions(self) -> set[str]:
        """
        File extensions used by the field

        :return: set of file extensions
        """
        return set("".join(file.suffixes) for file in self.files)

    def __contains__(self, item: Path) -> bool:
        return item in self.files

    def add(self, value: Path | PathLike[str]) -> None:
        # Make sure the value is a pathlib.Path
        if not isinstance(value, Path):
            value = Path(value)
        # Make sure to add the path value as an absolute path
        if not value.is_absolute():
            # If it's relative it must be relative to the OutputField.root_path
            value = self.parent.root_path / value
        self.files.add(value)

    def discard(self, value: Path | PathLike[str]) -> None:
        # See add method comments
        if not isinstance(value, Path):
            value = Path(value)
        if not value.is_absolute():
            value = self.parent.root_path / value
        self.files.discard(value)

    def __len__(self) -> int:
        return len(self.files)

    def __iter__(self) -> Iterator[Path]:
        return iter(self.files)

    def with_extension(self, ext: str) -> Path:
        if not ext.startswith("."):
            ext = "." + ext
        if ext and ext not in self.extensions:
            raise FileNotFoundError(
                f"Could not find field_file with extension '{ext}' for field"
                f" '{self.parent.field}'"
            )
        return next(f for f in self.files if f.name.endswith(ext))


@attrs.define(frozen=True)
class OutputField:
    """
    Output field (files) generated by Octopus

    Can either have:

    - a :py:class:`FieldFiles` in :py:attr:`files`, thus representing a single "static"
      field
    - a map of iterations and :py:class:`FieldFiles` in :py:attr:`iterations`,
      representing a series of fields at different iteration steps (time or scf steps)
    - a map of other quantities and :py:class:`FieldFiles` in :py:attr:`other_index`,
      representing a field that is indexed by other quantities

    For example, the :py:class:`OutputField` of the wave functions `wf` item can be
    nested as follows:

    .. code-block:: python
       @attrs.frozen
       class WFState(OtherIndex):
         st: int
         k: int
         sp: int

       calc_mode = CalcModeFiles("scf", Path("."))
       wf = calc_mode.get_or_init("wf")
       wf_iter = wf.iterations.setdefault(0,OutputField(wf))
       wf_state = wf_iter.other_index.setdefault(WFState(1, 3, 2), OutputField(wf_iter))
       wf_state.files.add(Path("output_iter/td.0000/wf-k0001-st0003-sp0002.ncdf"))
    """

    parent: OutputField | CalcModeFiles = attrs.field()
    """
    Parent :py:class:`OutputField` that contains this field in :py:attr:`iterations` or
    :py:attr:`other_index`, or parent :py:class:`CalcModeFiles` that contains this field
    in :py:attr:`CalcModeFiles.field_map`
    """
    field: FieldName = attrs.field(
        default=attrs.Factory(lambda self: self.parent.field, takes_self=True)
    )
    """Unique field name (relative to system and calculation mode)"""

    @field.validator
    def is_valid_field(self, attribute, value) -> bool:
        if isinstance(self.parent, OutputField) and self.parent.field != value:
            raise ValueError(
                f"Value of `field` must be the same as its parent, but {self.parent.field!r} != {value!r}"
            )

    _index: Any = attrs.field(default=None)
    """Index in the parent collection.

    E.g.
    ```
    `field is field.parent.iterations[field._index]` yields True
    """

    files: FieldFiles = attrs.field(
        init=False,
        default=attrs.Factory(lambda self: FieldFiles(parent=self), takes_self=True),
    )
    """
    "Static" files that describe this OutputField

    .. seealso:: :py:attr:`iterations`, :py:attr:`other_index`
    """
    iterations: OutputFieldMap[int] = attrs.field(
        init=False,
        default=attrs.Factory(lambda self: OutputFieldMap(self), takes_self=True),
    )
    """
    Map of iterations and :py:class:`OutputField` related to `output_iter` folder

    .. seealso:: :py:attr:`files`, :py:attr:`other_index`
    """
    other_index: OutputFieldMap[OtherIndex] = attrs.field(
        init=False,
        default=attrs.Factory(lambda self: OutputFieldMap(self), takes_self=True),
    )
    """
    Map of other indices and :py:class:`OutputField` related to Octopus naming
    convention, e.g. `wf_kt0001_st0003`

    .. seealso:: :py:attr:`files`, :py:attr:`iterations`
    """

    def __repr__(self) -> str:
        if isinstance(self.parent, CalcModeFiles):
            return f"{self.parent!r}[{self.field!r}]"
        if self.parent.has_iterations():
            return f"{self.parent!r}.iterations[{self._index!r}]"
        if self.parent.has_other_index():
            return f"{self.parent!r}.other_index[{self._index!r}]"
        assert False

    @property
    def root_path(self) -> Path:
        """
        Path to the system root (output)

        .. seealso:: :py:attr:`CalcModeFiles.root_path`
        """
        return self.parent.root_path

    def is_static(self) -> bool:
        """
        Check if OutputField is static, i.e. has native files outside of iterations
        """
        return len(self.files) > 0

    def has_iterations(self, check_valid: bool = False) -> bool:
        """
        Check if OutputField has (valid) iteration files

        :param check_valid: Whether to check if the fields inside are valid
        """
        if len(self.iterations) == 0:
            return False
        if not check_valid:
            # If we don't need to check that the other fields are valid can report that
            # it is true
            return True
        return all(field.is_valid() for field in self.iterations.values())

    def has_other_index(self, check_valid: bool = False) -> bool:
        """
        Check if OutputField has other indexed files

        :param check_valid: Whether to check if the fields inside are valid
        """
        if len(self.other_index) == 0:
            return False
        if not check_valid:
            # If we don't need to check that the other fields are valid can report that
            # it is true
            return True
        return all(field.is_valid() for field in self.other_index.values())

    def is_valid(self) -> bool:
        """
        Check if OutputField is valid (contains some file), checking recursively all
        maps
        """
        # First check that the field has only one of static/iterations/other_index
        if (
            sum(
                [
                    self.is_static(),
                    self.has_iterations(check_valid=False),
                    self.has_other_index(check_valid=False),
                ]
            )
            != 1
        ):
            return False
        # Check that the fields are actually valid
        return (
            sum(
                [
                    self.is_static(),
                    self.has_iterations(check_valid=True),
                    self.has_other_index(check_valid=True),
                ]
            )
            == 1
        )

    def all_other_index(self) -> Iterator[OtherIndex]:
        """
        Get recursively all :py:class:`OtherIndex` keys in the :py:attr:`other_index`
        attributes, navigating through :py:attr:`iterations` if necessary.

        :return: Iterator of all :py:attr:`other_index` OtherIndex
        """
        if self.is_static():
            return
        if self.has_iterations():
            for field in self.iterations.values():
                yield from field.all_other_index()
        if self.has_other_index():
            yield from self.other_index.keys()

    def is_vector(self) -> bool:
        """
        Check if the field is a vector type by checking its :py:class:`FieldFiles`
        """
        if self.has_other_index():
            return all(isinstance(k, VectorDimension) for k in self.other_index.keys())
        if self.has_iterations():
            return self.iterations.get_any().is_vector()
        return False

    @property
    def calc_mode(self) -> CalcModeFiles:
        """
        Root :py:class:`CalcModeFiles` that owns this field
        """
        if isinstance(self.parent, CalcModeFiles):
            return self.parent
        assert isinstance(self.parent, OutputField)
        return self.parent.calc_mode

    def get_any_field_files(self) -> FieldFiles:
        """Traverse the tree structure of the output and fetch a node containing files.
        There is no guarantee which of the field files is returned
        (could be the files of any iteration or index, not necessarily the first).
        """
        output = self
        # The output collector *should* be structured as a tree.
        # But in case of a programming error it could happen that it contains a
        # circular reference (e.g. A.other_index[idx1] -> B, B.other_index[idx2] -> A).
        # To avoid an endless loop, limit the nesting depth to some high random number.
        for _ in range(1024):
            if output.is_static():
                return output.files
            output = output.iterations.get_any() or output.other_index.get_any()
        raise RuntimeError("Nesting depth exceeded.")


@attrs.define(frozen=True)
class OutputFieldMap(MutableMapping["KT", OutputField]):
    """
    Generic map of (frozen) indices and :py:class:`OutputField`

    These map the information of `output_iter` and Octopus file format convention to the
    files representing the specific field
    """

    parent: OutputField = attrs.field()
    """
    :py:class:`OutputField` that owns this OutputFieldMap
    """
    field_map: dict[KT, OutputField] = attrs.field(init=False, factory=dict)
    """Actual map object"""

    # TODO: Have a mechanism to ensure the indices are frozen

    def __getitem__(self, __key: KT) -> OutputField:
        return self.field_map[__key]

    def __setitem__(self, __key: KT, __value: OutputField) -> None:
        self.field_map[__key] = __value

    def __delitem__(self, __key: KT) -> None:
        del self.field_map[__key]

    def __len__(self) -> int:
        return len(self.field_map)

    def __iter__(self) -> Iterator[int]:
        return iter(self.field_map)

    def setdefault(self, key, default: OutputField | None = None) -> OutputField:
        if default is None:
            return self.field_map.setdefault(key, OutputField(self.parent, index=key))
        if not isinstance(default, OutputField):
            raise TypeError(f"Unsupported default value type {type(default)}")
        return self.field_map.setdefault(key, default)

    def get_any(self) -> OutputField | None:
        return next(iter(self.values()), None)


@attrs.define
class CalcModeFiles(MutableMapping["FieldName", OutputField]):
    """
    CalcMode container of all :py:class:`OutputField` in the current calculation
    mode/system
    """

    calc_mode: CalcModeName
    """CalcMode of the set of files"""
    system: System
    """System containing these files"""
    fields: dict[FieldName, OutputField] = attrs.field(init=False, factory=dict)
    """List (actually map) of all the fields available in the CalcMode"""

    def __repr__(self) -> str:
        return f"{self.system!r}[{self.calc_mode!r}]"

    @property
    def root_path(self) -> Path:
        return self.system.path

    def get_or_init(self, field: FieldName) -> OutputField:
        """
        Get or initialize an :py:class:`OutputField`

        :param field: Name of the output field
        :return: :py:class:`OutputField` in
        """
        return self.fields.setdefault(field, OutputField(self, field))

    def __getitem__(self, __key: FieldName) -> OutputField:
        return self.fields[__key]

    def __setitem__(self, key: FieldName, value: OutputField) -> None:
        if key != value.field:
            raise ValueError(
                f"Key is not equivalent to field value's name: {key} != {value.field}"
            )
        self.fields[key] = value

    def __delitem__(self, __key: FieldName) -> None:
        del self.fields[__key]

    def __len__(self) -> int:
        return len(self.fields)

    def __iter__(self) -> Iterator[FieldName]:
        return iter(self.fields)

    def add_files(
        self,
        file_list: list[Path],
        root_path: Path | None = None,
        iternum: IterationNum | None = None,
    ) -> None:
        for file in file_list:
            self.add_file(file, root_path, iternum)

    def add_file(
        self,
        file: Path,
        root_path: Path | None = None,
        iternum: IterationNum | None = None,
    ):
        if pattern := should_ignore_path(file):
            logger.debug("Ignoring file %s matching pattern %s", file, pattern)
            return

        extension = "".join(file.suffixes)
        relative_name = file
        if root_path:
            relative_name = relative_name.relative_to(root_path)
        field_name = str(relative_name).removesuffix(extension)
        indices = None
        field_file_info = FieldFileInfo(file, field_name, extension)
        if (match := OtherIndex.find_match(field_file_info)) is not None:
            field_name, indices = match

        field_name = field_name.replace("-", "_")
        field = self.get_or_init(field_name)

        if iternum is not None:
            field = field.iterations.setdefault(iternum)

        if indices is not None:
            # `OtherIndex.find_match` either returns a single index or a list
            # of indices. In case of multiple indices the file is added to all
            # other_index entries.
            # E.g. if a '.vtk' file contains multiple components it is added to
            # all `field.other_index['x'].files`, `field.other_index['y'].files`
            # and `field.other_index['z'].files`.
            if not isinstance(indices, list):
                indices = [indices]
            for index in indices:
                index_field = field.other_index.setdefault(index)
                index_field.files.add(file.absolute())
        else:
            field.files.add(file.absolute())


@attrs.define
class System(MutableMapping["CalcModeName", CalcModeFiles]):
    """Container of all :py.class:`CalcModeFiles` in the current system"""

    name: SystemName
    """Name of the system."""
    path: Path
    """Root path of the system's output"""
    calculation_modes: dict[CalcModeName, CalcModeFiles] = attrs.field(
        init=False,
        factory=dict,
        on_setattr=attrs.setters.frozen,
        repr=False,
    )

    def __getitem__(self, key: CalcModeName) -> CalcModeFiles:
        return self.calculation_modes[key]

    def __setitem__(self, key: CalcModeName, value: CalcModeFiles) -> None:
        if key != value.calc_mode:
            raise ValueError(
                f"Key is not equivalent to calculation mode's name: {key} != {value.calc_mode}"
            )
        self.calculation_modes[key] = value

    def __delitem__(self, key: CalcModeName) -> None:
        del self.calculation_modes[key]

    def __len__(self) -> int:
        return len(self.calculation_modes)

    def __iter__(self) -> Iterator[CalcModeName]:
        return iter(self.calculation_modes)

    def setdefault(
        self, key: SystemName, default: CalcModeFiles | None = None
    ) -> CalcModeFiles:
        if default is None:
            return self.calculation_modes.setdefault(key, CalcModeFiles(key, self))
        if not isinstance(default, CalcModeFiles):
            raise TypeError(f"Unsupported default value type {type(default)}")
        return super().setdefault(key, default)


@attrs.define
class OutputCollector:
    """
    Will search for all output of Octopus in the given path. Finds system names,
    calculation modes and written fields.
    """

    rootpath: Path = attrs.field(on_setattr=attrs.setters.frozen, converter=Path)
    """Path to the Octopus output containing inp file"""
    output: dict[SystemName, System] = attrs.field(
        init=False, factory=dict, on_setattr=attrs.setters.frozen
    )
    """Output field files defined in the :py:attr:`rootpath` folder"""
    _config: Parser = attrs.field(
        init=False,
        default=attrs.Factory(
            lambda self: Parser(self.rootpath / "inp"), takes_self=True
        ),
    )
    """Octopus parsed input file"""
    _filesystem_systems: list[SystemName] = attrs.field(init=False)

    def __attrs_post_init__(self) -> None:
        for system in self._filesystem_systems:
            self.output[system] = self.find_iterations(system)

    @_filesystem_systems.default
    def find_systems(self) -> list[SystemName]:
        """Find all systems present in the output.

        Returns
        -------
        list[str]
            list with all systems in the output.

        """
        systems_in_conf = self._config.systems.keys()
        systems_in_FS = []
        for system_name in systems_in_conf:
            # compatible with single and multisystems
            if (
                Path(self.rootpath, *system_name.split(".")).is_dir()
                or system_name == "default"
            ):
                systems_in_FS.append(system_name)
        return systems_in_FS

    def find_iterations(self, system_name: SystemName) -> System:
        """Find available iterations per calculation mode for a system.

        Parameters
        ----------
        system : str
            Name of the system, for which iterations shall be found

        Returns
        -------
        dict[str, dict[str, list[Path] | tuple[str, list[str]]]]
            dict in dict, outer dict has calculation modes as keys, every
            calculation mode dict has a dict with tuples
            (iteration number, files list) as values and key "iterations". Also
            looks for data in folders "static" and "td.general".
        Notes
        -----
        Iterations namedtuples have the following form:
        >> Iterations(iteration_number='0000021',
         fields=['current-z', 'current-x', 'density', 'current-y'],
          extensions=['ncdf'])

        """
        if system_name == "default":
            system_path = self.rootpath
        else:
            # compatible with single and multisystems
            system_path = Path(self.rootpath, *system_name.split("."))

        ##########
        # Find all output files. We need a list of all outputs from every calculation
        # mode.
        ##########
        system = System(system_name, system_path)
        for folder in system_path.glob("*/"):
            collector = Collector(folder, system)
            collector.collect()
        return system


class _DummyCollector:
    def collect(self):
        pass


class Collector(abc.ABC):
    _collector_map: dict[Path, Collector] = dict()

    __path__: ClassVar[Path] = None
    """Path name the collector should handle.
    E.g. if set to `td.general` the collector is invoked for
    the Path `{system_path}/td.general`.
    """

    def __init_subclass__(cls, /, **kwargs):
        super().__init_subclass__(**kwargs)
        if cls.__path__ is not None:
            if not isinstance(cls.__path__, Path):
                raise TypeError(
                    f"`__path__` must be of type `pathlib.Path` or None, not {type(cls.__path__)}."
                )
            cls._collector_map[cls.__path__] = cls

    def __new__(cls, path: Path, system: System):
        path_name = path.relative_to(system.path)
        if path_name in cls._collector_map:
            cls = cls._collector_map[path_name]
        else:
            cls = _DummyCollector
        return object.__new__(cls)

    def __init__(self, path: Path, system: System):
        self.path = path
        self.system = system

    @abc.abstractclassmethod
    def collect(self) -> None:
        """Collect all relevant files in `self.path` and provide them
        in `self.system` by using `CalcModeFiles.add_files`.
        """


class CollectOutputIter(Collector):
    __path__ = Path("output_iter/")

    def collect(self):
        """Get the list of all files in output_iter"""

        if not self.path.is_dir():
            logger.warning("Expected %s to be a directory. Skipping.", self.path)
            return

        # First iteration folder structure are f"{calcmode}.{iternum}"
        for iter_folder in self.path.glob("*/"):
            # Only for python3.11 pathlib returns only directories when the pattern end with "/"
            # (see https://docs.python.org/3/library/pathlib.html#pattern-language)
            if not iter_folder.is_dir():
                continue
            # Ignore folders like __pycache__.
            if pattern := should_ignore_path(iter_folder):
                logger.debug(
                    "Ignoring folder %s matching pattern %s", iter_folder, pattern
                )
                continue

            name_split = iter_folder.name.split(".")
            if len(name_split) != 2:
                logger.warning(
                    "Skipping folder %s due to unexpected format.", iter_folder
                )
                continue

            calcmode = name_split[0]
            try:
                iternum = int(name_split[1])
            except ValueError:
                logger.warning(
                    "Skipping folder %s due to unexpected format.", iter_folder
                )
                continue

            calc_mode_output = self.system.setdefault(calcmode)
            files = (f for f in iter_folder.rglob("*") if f.is_file())
            calc_mode_output.add_files(files, root_path=iter_folder, iternum=iternum)


class CollectStatic(Collector):
    __path__ = Path("static/")

    def collect(self):
        outputs_calc_mode = self.system.setdefault("scf")
        files = set(self.path.rglob("*"))
        files_with_ext = set(f for f in files if "." in f.name)
        files_without_ext = files - files_with_ext
        # Files with an extension are considered as field where corresponding files exists in output_iter/
        outputs_calc_mode.add_files(
            files_with_ext,
            root_path=self.path,
            iternum=STATIC_ITERNUM,
        )
        outputs_calc_mode.add_files(
            files_without_ext,
            root_path=self.path,
            iternum=None,
        )


class CollectTDGeneral(Collector):
    __path__ = Path("td.general/")

    def collect(self):
        outputs_calc_mode = self.system.setdefault("td")
        files = self.path.rglob("*")
        outputs_calc_mode.add_files(files, root_path=self.path)


class CollectProfiling(Collector):
    """Enable reading of profiling timing data

    This only supports the default case of one timing output from the
    first rank. There is an option in octopus to write out one output
    from each rank to different files with the corresponding number
    in the file name. This is rarely used, so we do not need to support
    it right now.
    Also, it only reads the data created with "ProfilingMode = prof_time".
    """

    __path__ = Path("profiling/")

    def collect(self):
        calc_mode = self.system.setdefault("profiling")
        profiling_file = self.path / "time.000000"
        if profiling_file.exists():
            calc_mode.add_file(profiling_file, root_path=self.path)
