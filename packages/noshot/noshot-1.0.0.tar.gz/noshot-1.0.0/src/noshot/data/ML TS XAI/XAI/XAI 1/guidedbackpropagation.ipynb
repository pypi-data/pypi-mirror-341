{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "t71r0zijG0_7",
    "outputId": "e772d9a6-eaf7-4363-b00a-4e46913ae149"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Custom Guided Backpropagation ReLU\n",
    "class GuidedBackpropReLU(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return torch.relu(input)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        grad_input = torch.clamp(grad_output, min=0.0)\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "# Replace ReLU with GuidedBackpropReLU\n",
    "def replace_relu_with_guided(model):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, nn.ReLU):\n",
    "            setattr(model, name, GuidedBackpropReLU())\n",
    "        else:\n",
    "            replace_relu_with_guided(module)\n",
    "\n",
    "\n",
    "# Preprocess the input image\n",
    "def preprocess_image(image_path):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    return preprocess(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "\n",
    "# Guided Backpropagation function\n",
    "def guided_backpropagation(model, input_image, target_class):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    input_image.requires_grad = True  # Enable gradient computation for input\n",
    "\n",
    "    replace_relu_with_guided(model)  # Replace all ReLU activations\n",
    "\n",
    "    output = model(input_image)  # Forward pass\n",
    "    loss = output[0, target_class]  # Target class loss\n",
    "    model.zero_grad()  # Zero out gradients\n",
    "    loss.backward()  # Backward pass\n",
    "\n",
    "    return input_image.grad.data  # Return gradients w.r.t. input image\n",
    "\n",
    "\n",
    "# Visualize the gradients\n",
    "def visualize_gradients(gradients):\n",
    "    gradients = gradients[0].cpu().numpy()  # Remove batch dimension\n",
    "    gradients = np.moveaxis(gradients, 0, -1)  # Rearrange channels to last dimension\n",
    "    gradients = (gradients - gradients.min()) / (gradients.max() - gradients.min())  # Normalize\n",
    "    plt.imshow(gradients)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    # Load a pretrained model\n",
    "    model = models.vgg16(pretrained=True)\n",
    "\n",
    "    # Load and preprocess the input image\n",
    "    image_path = \"/content/g2.jpeg\"  # Replace with the path to your image\n",
    "    input_image = preprocess_image(image_path)\n",
    "\n",
    "    # Define target class (e.g., 'bull mastiff' class in ImageNet)\n",
    "    target_class = 243\n",
    "\n",
    "    # Move to device (CPU/GPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    input_image = input_image.to(device)\n",
    "\n",
    "    # Perform Guided Backpropagation\n",
    "    gradients = guided_backpropagation(model, input_image, target_class)\n",
    "\n",
    "    # Visualize the gradients\n",
    "    visualize_gradients(gradients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x5z8OBtLIqWh"
   },
   "outputs": [],
   "source": [
    "gradients = (gradients - gradients.min()) / (gradients.max() - gradients.min())  # Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tIlhZt2SIt8S",
    "outputId": "d22fdb34-f725-41d1-9117-5a8456daddbc"
   },
   "outputs": [],
   "source": [
    "print(\"Gradient shape:\", gradients.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PxPrybk2JQdQ",
    "outputId": "f3e1ed74-8b5b-476c-e70e-f682a528d2a1"
   },
   "outputs": [],
   "source": [
    "output = model(input_image)\n",
    "print(\"Model output:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hOjkXsMrJZF3",
    "outputId": "65173d32-1016-4616-dfd4-3cb6cc858615"
   },
   "outputs": [],
   "source": [
    "gradients = guided_backpropagation(model, input_image, target_class)\n",
    "print(\"Gradients shape:\", gradients.shape)  # Should be [1, 3, 224, 224] for a single image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "dXeuco_bJd8h",
    "outputId": "f7bef501-ada9-4afb-8531-c069bd1d417a"
   },
   "outputs": [],
   "source": [
    "plt.imshow(gradients[0].cpu().numpy()[0], cmap='hot')  # Display the first channel's gradients\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
