{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a956d239-b4b0-4e65-ac1a-d8047cfc883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d4f98-bfb5-40a0-9c0e-8843361cb7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c323e6e-58bf-498a-bc60-1e02a1aea4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 32 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e73bc1-cbfb-46ca-b5d2-4798b8b59a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, criterion, optimizer, epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)  # CNN outputs (logits)\n",
    "\n",
    "            # Print CNN output (logits) for the first image in the batch\n",
    "            print(f\"Logits for first image in batch: {outputs[0]}\")  # First image in the batch\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(trainloader):.4f}\")\n",
    "\n",
    "train(model, trainloader, criterion, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b6189f-889e-419e-95d6-9154c2acca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(model, dataloader):\n",
    "    model.eval()\n",
    "    features, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, lbls in dataloader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)  # CNN outputs (logits)\n",
    "\n",
    "            # Print CNN outputs (logits) for the first image in each batch\n",
    "            print(f\"Logits for first image in batch: {outputs[0]}\")  # This will print the logits for the first image\n",
    "\n",
    "            features.extend(outputs.cpu().numpy())  # Extract CNN outputs as features\n",
    "            labels.extend(lbls.numpy())\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "X_train, y_train = extract_features(model, trainloader)\n",
    "X_test, y_test = extract_features(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44442993-376b-41c0-9dc9-f55cfdc0268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=5)  \n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "acc = dt.score(X_test, y_test)\n",
    "print(f\"Surrogate Model Accuracy: {acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bb7a9f-b4ba-4bc1-95ef-ecd1cf525b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_surrogate_model(dt):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_tree(dt, filled=True, feature_names=[f\"Feature {i}\" for i in range(X_train.shape[1])], class_names=[str(i) for i in range(10)], rounded=True)\n",
    "    plt.title(\"Surrogate Model - Decision Tree\")\n",
    "    plt.show()\n",
    "\n",
    "visualize_surrogate_model(dt)\n",
    "\n",
    "\n",
    "def plot_feature_importance(dt, feature_names):\n",
    "    feature_importances = dt.feature_importances_\n",
    "    indices = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Feature Importances (Surrogate Model)\")\n",
    "    plt.barh(range(X_train.shape[1]), feature_importances[indices], align=\"center\")\n",
    "    plt.yticks(range(X_train.shape[1]), [f\"Feature {i}\" for i in indices])\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_feature_importance(dt, [f\"Feature {i}\" for i in range(X_train.shape[1])])\n",
    "\n",
    "\n",
    "\n",
    "def visualize_feature_maps(model, input_image):\n",
    "    model.eval()\n",
    "    layers = [model.conv1, model.conv2]\n",
    "    activations = []\n",
    "\n",
    "    def save_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activations.append(output)\n",
    "        return hook\n",
    "\n",
    "   \n",
    "    hooks = []\n",
    "    for layer in layers:\n",
    "        hooks.append(layer.register_forward_hook(save_activation(layer.__class__.__name__)))\n",
    "\n",
    "   \n",
    "    input_image = input_image.unsqueeze(0).to(device)\n",
    "    model(input_image)\n",
    "\n",
    "   \n",
    "    for i, activation in enumerate(activations):\n",
    "        activation = activation.squeeze(0).cpu().detach().numpy()\n",
    "        num_filters = activation.shape[0]\n",
    "\n",
    "        \n",
    "        fig, axes = plt.subplots(1, num_filters, figsize=(15, 8))\n",
    "        for j in range(num_filters):\n",
    "            axes[j].imshow(activation[j], cmap='gray')\n",
    "            axes[j].axis('off')\n",
    "            axes[j].set_title(f\"Filter {j + 1}\")\n",
    "        plt.show()\n",
    "\n",
    "   \n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "\n",
    "sample_image, sample_label = testset[0]\n",
    "visualize_feature_maps(model, sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d572de18-1df8-41b8-8b24-618790d7d0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
